{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zWseivb1lli"
      },
      "source": [
        "## General Colab Tips\n",
        "- Modify files by opening/editing them in the UI (double-click to open).\n",
        "- `Right click > Refresh` in the Colab file explorer to update the directory.\n",
        "- All files are lost when the Colab session disconnects, so make sure back up your work.\n",
        "- Do **not** use `drive.mount` for your datasets! Reading from GDrive is super slow.\n",
        "- Instead, place datasets into the `/content/` folder and modify your data accordingly.\n",
        "\n",
        "**Make a copy of this notebook and modify this to whatever workflow you prefer!**\n",
        "\n",
        "If you have some additional colab tips, please share them on the discussion forum.\n",
        "\n",
        "## Setup\n",
        "\n",
        "First, enable a GPU runtime via `Runtime > Change runtime type > T4 GPU`\n",
        "\n",
        "Next, upload the your project files to the Colab. You can do this by either\n",
        "- using Github (**recommended**)\n",
        "- uploading files manually using the UI\n",
        "\n",
        "## Github Setup\n",
        "\n",
        "You can use git from within Google Colab!\n",
        "\n",
        "For this section, we assume you know how to use git and have already pushed the starter code to a private repo.\n",
        "\n",
        "Before you continue, make sure you download and push the starter code to your repo.  \n",
        "It's a good idea to structure your repo something like\n",
        "```\n",
        "online_deep_learning/\n",
        "    homework1/\n",
        "    homework2/\n",
        "    ...\n",
        "```\n",
        "\n",
        "We highly recommend using this workflow as you'll be able to easily pull/commit your changes after modifying your model on Colab.\n",
        "\n",
        "To do this, you'll need a personal access token from [https://github.com/settings/tokens](https://github.com/settings/tokens)\n",
        "\n",
        "The easiest thing to do is select \"classic\" token and make sure you have the `repo` scope selected to allow access to your private repos.\n",
        "There's also fine-grained tokens where you can select access to specific repos.\n",
        "\n",
        "Once you have your token, fill in your information and then run the following cell to clone your git repo to the Colab instance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gxzo13BN6FL0"
      },
      "source": [
        "## Code Setup\n",
        "\n",
        "Move into `homework4/` so we can continue setting up the data / code for training.\n",
        "\n",
        "This will be the main working directory and the training/grading must be run from this directory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "et3KFSXs3IHk",
        "outputId": "04ee25a4-d4ee-4e3f-9354-1334870a7e74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/advances_in_deep_learning\n",
            "\u001b[0m\u001b[01;34mhomework1\u001b[0m/  \u001b[01;34mhomework2\u001b[0m/  \u001b[01;34mhomework3\u001b[0m/  \u001b[01;34mhomework4\u001b[0m/\n",
            "/content/advances_in_deep_learning/homework1\n",
            "bignet.pth  \u001b[0m\u001b[01;34mgrader\u001b[0m/    Homework1.ipynb  requirements.txt\n",
            "bundle.py   \u001b[01;34mhomework\u001b[0m/  README.md\n"
          ]
        }
      ],
      "source": [
        "# navigate to your repo\n",
        "%cd /content/{os.environ['REPO']}\n",
        "%ls\n",
        "\n",
        "# go to a specific homework\n",
        "%cd homework1\n",
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Q4sbuDqn3tq",
        "outputId": "c8ec4894-3f95-4ee5-ce30-7a8509098598"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch>=2.4.1 in /usr/local/lib/python3.12/dist-packages (from -r ./requirements.txt (line 1)) (2.9.0+cu126)\n",
            "Requirement already satisfied: numpy>=2.2.1 in /usr/local/lib/python3.12/dist-packages (from -r ./requirements.txt (line 2)) (2.4.1)\n",
            "Requirement already satisfied: termcolor>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from -r ./requirements.txt (line 3)) (3.3.0)\n",
            "Requirement already satisfied: fire>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from -r ./requirements.txt (line 4)) (0.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->-r ./requirements.txt (line 1)) (3.20.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->-r ./requirements.txt (line 1)) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->-r ./requirements.txt (line 1)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->-r ./requirements.txt (line 1)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->-r ./requirements.txt (line 1)) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->-r ./requirements.txt (line 1)) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->-r ./requirements.txt (line 1)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->-r ./requirements.txt (line 1)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->-r ./requirements.txt (line 1)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->-r ./requirements.txt (line 1)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->-r ./requirements.txt (line 1)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->-r ./requirements.txt (line 1)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->-r ./requirements.txt (line 1)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->-r ./requirements.txt (line 1)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->-r ./requirements.txt (line 1)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->-r ./requirements.txt (line 1)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->-r ./requirements.txt (line 1)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->-r ./requirements.txt (line 1)) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->-r ./requirements.txt (line 1)) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->-r ./requirements.txt (line 1)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->-r ./requirements.txt (line 1)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->-r ./requirements.txt (line 1)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->-r ./requirements.txt (line 1)) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.4.1->-r ./requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.4.1->-r ./requirements.txt (line 1)) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r ./requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLe2Ti0xJeIL",
        "outputId": "c12b728d-feee-4a7b-d56e-03f6f19daecc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model:\n",
            "MLPPlanner(\n",
            "  (net): Sequential(\n",
            "    (0): Linear(in_features=40, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=128, out_features=6, bias=True)\n",
            "  )\n",
            ")\n",
            "Loaded 8000 samples from 16 episodes\n",
            "Loaded 2000 samples from 4 episodes\n",
            "Epoch 1/100 | Train Loss: 4.5608 | Val Loss: 2.8744 | Long: 0.2007 | Lat: 1.2896 | Coverage: 1.4902\n",
            "Saved new best model with lateral_error = 1.2896\n",
            "Epoch 2/100 | Train Loss: 4.1251 | Val Loss: 1.9969 | Long: 0.1900 | Lat: 0.9740 | Coverage: 1.1641\n",
            "Saved new best model with lateral_error = 0.9740\n",
            "Epoch 3/100 | Train Loss: 4.0332 | Val Loss: 1.7951 | Long: 0.1697 | Lat: 0.9746 | Coverage: 1.1443\n",
            "Epoch 4/100 | Train Loss: 4.0224 | Val Loss: 1.9099 | Long: 0.1876 | Lat: 0.9989 | Coverage: 1.1865\n",
            "Epoch 5/100 | Train Loss: 4.0197 | Val Loss: 1.3243 | Long: 0.1528 | Lat: 0.7460 | Coverage: 0.8988\n",
            "Saved new best model with lateral_error = 0.7460\n",
            "Epoch 6/100 | Train Loss: 4.0563 | Val Loss: 3.5417 | Long: 0.1639 | Lat: 1.5829 | Coverage: 1.7468\n",
            "Epoch 7/100 | Train Loss: 3.9628 | Val Loss: 3.3905 | Long: 0.2729 | Lat: 1.5018 | Coverage: 1.7748\n",
            "Epoch 8/100 | Train Loss: 4.0189 | Val Loss: 2.7339 | Long: 0.1611 | Lat: 1.3313 | Coverage: 1.4925\n",
            "Epoch 9/100 | Train Loss: 4.0450 | Val Loss: 1.2489 | Long: 0.1602 | Lat: 0.6937 | Coverage: 0.8540\n",
            "Saved new best model with lateral_error = 0.6937\n",
            "Epoch 10/100 | Train Loss: 3.9619 | Val Loss: 1.8234 | Long: 0.1444 | Lat: 0.9994 | Coverage: 1.1437\n",
            "Epoch 11/100 | Train Loss: 3.9492 | Val Loss: 1.7531 | Long: 0.1403 | Lat: 0.9344 | Coverage: 1.0747\n",
            "Epoch 12/100 | Train Loss: 4.0181 | Val Loss: 1.7526 | Long: 0.1617 | Lat: 0.9522 | Coverage: 1.1139\n",
            "Epoch 13/100 | Train Loss: 3.9234 | Val Loss: 1.7274 | Long: 0.1502 | Lat: 0.9358 | Coverage: 1.0859\n",
            "Epoch 14/100 | Train Loss: 3.9232 | Val Loss: 1.8821 | Long: 0.1451 | Lat: 1.0057 | Coverage: 1.1508\n",
            "Epoch 15/100 | Train Loss: 3.9191 | Val Loss: 3.1976 | Long: 0.1394 | Lat: 1.4834 | Coverage: 1.6228\n",
            "Epoch 16/100 | Train Loss: 3.9215 | Val Loss: 2.9267 | Long: 0.1368 | Lat: 1.3948 | Coverage: 1.5316\n",
            "Epoch 17/100 | Train Loss: 3.9125 | Val Loss: 2.1979 | Long: 0.1380 | Lat: 1.1370 | Coverage: 1.2751\n",
            "Epoch 18/100 | Train Loss: 3.9177 | Val Loss: 1.3163 | Long: 0.1321 | Lat: 0.7094 | Coverage: 0.8415\n",
            "Epoch 19/100 | Train Loss: 3.9003 | Val Loss: 1.8936 | Long: 0.1908 | Lat: 0.9822 | Coverage: 1.1730\n",
            "Epoch 20/100 | Train Loss: 3.8854 | Val Loss: 1.4333 | Long: 0.1428 | Lat: 0.7585 | Coverage: 0.9013\n",
            "Epoch 21/100 | Train Loss: 3.8912 | Val Loss: 3.2053 | Long: 0.1574 | Lat: 1.4698 | Coverage: 1.6272\n",
            "Epoch 22/100 | Train Loss: 3.9325 | Val Loss: 1.4613 | Long: 0.1925 | Lat: 0.7821 | Coverage: 0.9745\n",
            "Epoch 23/100 | Train Loss: 3.8399 | Val Loss: 1.6445 | Long: 0.1640 | Lat: 0.8858 | Coverage: 1.0499\n",
            "Epoch 24/100 | Train Loss: 3.8982 | Val Loss: 2.4196 | Long: 0.1391 | Lat: 1.1882 | Coverage: 1.3273\n",
            "Epoch 25/100 | Train Loss: 3.8604 | Val Loss: 2.5161 | Long: 0.1467 | Lat: 1.2575 | Coverage: 1.4042\n",
            "Epoch 26/100 | Train Loss: 3.8590 | Val Loss: 1.7698 | Long: 0.1590 | Lat: 0.9311 | Coverage: 1.0901\n",
            "Epoch 27/100 | Train Loss: 3.8488 | Val Loss: 1.3793 | Long: 0.1365 | Lat: 0.7856 | Coverage: 0.9222\n",
            "Epoch 28/100 | Train Loss: 3.8363 | Val Loss: 2.0723 | Long: 0.1518 | Lat: 1.0842 | Coverage: 1.2360\n",
            "Epoch 29/100 | Train Loss: 3.8258 | Val Loss: 2.1541 | Long: 0.1416 | Lat: 1.1313 | Coverage: 1.2729\n",
            "Epoch 30/100 | Train Loss: 3.8512 | Val Loss: 1.6518 | Long: 0.1577 | Lat: 0.8931 | Coverage: 1.0508\n",
            "Epoch 31/100 | Train Loss: 3.8186 | Val Loss: 1.7565 | Long: 0.1441 | Lat: 0.9689 | Coverage: 1.1130\n",
            "Epoch 32/100 | Train Loss: 3.8010 | Val Loss: 1.7283 | Long: 0.1437 | Lat: 0.9408 | Coverage: 1.0845\n",
            "Epoch 33/100 | Train Loss: 3.8237 | Val Loss: 1.1623 | Long: 0.1495 | Lat: 0.6280 | Coverage: 0.7775\n",
            "Saved new best model with lateral_error = 0.6280\n",
            "Epoch 34/100 | Train Loss: 3.7839 | Val Loss: 1.5691 | Long: 0.1361 | Lat: 0.8466 | Coverage: 0.9827\n",
            "Epoch 35/100 | Train Loss: 3.7732 | Val Loss: 2.6797 | Long: 0.1421 | Lat: 1.3075 | Coverage: 1.4496\n",
            "Epoch 36/100 | Train Loss: 3.7318 | Val Loss: 1.2668 | Long: 0.1372 | Lat: 0.7172 | Coverage: 0.8544\n",
            "Epoch 37/100 | Train Loss: 3.7480 | Val Loss: 1.5431 | Long: 0.1444 | Lat: 0.8694 | Coverage: 1.0138\n",
            "Epoch 38/100 | Train Loss: 3.7264 | Val Loss: 1.2554 | Long: 0.1571 | Lat: 0.7250 | Coverage: 0.8821\n",
            "Epoch 39/100 | Train Loss: 3.7509 | Val Loss: 1.2465 | Long: 0.1498 | Lat: 0.7088 | Coverage: 0.8586\n",
            "Epoch 40/100 | Train Loss: 3.7239 | Val Loss: 1.5299 | Long: 0.1661 | Lat: 0.8550 | Coverage: 1.0211\n",
            "Epoch 41/100 | Train Loss: 3.6752 | Val Loss: 1.2876 | Long: 0.1403 | Lat: 0.7521 | Coverage: 0.8924\n",
            "Epoch 42/100 | Train Loss: 3.7066 | Val Loss: 1.9589 | Long: 0.1339 | Lat: 1.0568 | Coverage: 1.1907\n",
            "Epoch 43/100 | Train Loss: 3.6978 | Val Loss: 1.9031 | Long: 0.1435 | Lat: 1.0471 | Coverage: 1.1906\n",
            "Epoch 44/100 | Train Loss: 3.6754 | Val Loss: 1.5659 | Long: 0.1471 | Lat: 0.8821 | Coverage: 1.0293\n",
            "Epoch 45/100 | Train Loss: 3.6985 | Val Loss: 1.9003 | Long: 0.1608 | Lat: 1.0370 | Coverage: 1.1978\n",
            "Epoch 46/100 | Train Loss: 3.6590 | Val Loss: 1.9285 | Long: 0.1353 | Lat: 1.0591 | Coverage: 1.1944\n",
            "Epoch 47/100 | Train Loss: 3.6542 | Val Loss: 1.8738 | Long: 0.1394 | Lat: 1.0299 | Coverage: 1.1693\n",
            "Epoch 48/100 | Train Loss: 3.7037 | Val Loss: 1.4693 | Long: 0.1388 | Lat: 0.8450 | Coverage: 0.9837\n",
            "Epoch 49/100 | Train Loss: 3.6575 | Val Loss: 1.5844 | Long: 0.1397 | Lat: 0.8924 | Coverage: 1.0321\n",
            "Epoch 50/100 | Train Loss: 3.6400 | Val Loss: 1.0876 | Long: 0.1833 | Lat: 0.5769 | Coverage: 0.7602\n",
            "Saved new best model with lateral_error = 0.5769\n",
            "Epoch 51/100 | Train Loss: 3.7179 | Val Loss: 1.2496 | Long: 0.1479 | Lat: 0.7282 | Coverage: 0.8761\n",
            "Epoch 52/100 | Train Loss: 3.6462 | Val Loss: 2.2386 | Long: 0.1359 | Lat: 1.1720 | Coverage: 1.3079\n",
            "Epoch 53/100 | Train Loss: 3.6583 | Val Loss: 2.1248 | Long: 0.1571 | Lat: 1.1137 | Coverage: 1.2708\n",
            "Epoch 54/100 | Train Loss: 3.6406 | Val Loss: 1.6384 | Long: 0.1546 | Lat: 0.9201 | Coverage: 1.0747\n",
            "Epoch 55/100 | Train Loss: 3.6160 | Val Loss: 2.2218 | Long: 0.1432 | Lat: 1.1433 | Coverage: 1.2866\n",
            "Epoch 56/100 | Train Loss: 3.6166 | Val Loss: 1.6816 | Long: 0.1595 | Lat: 0.9070 | Coverage: 1.0665\n",
            "Epoch 57/100 | Train Loss: 3.6455 | Val Loss: 1.5532 | Long: 0.1355 | Lat: 0.8831 | Coverage: 1.0187\n",
            "Epoch 58/100 | Train Loss: 3.6501 | Val Loss: 1.7412 | Long: 0.1339 | Lat: 0.9700 | Coverage: 1.1040\n",
            "Epoch 59/100 | Train Loss: 3.6476 | Val Loss: 1.8539 | Long: 0.1453 | Lat: 1.0079 | Coverage: 1.1532\n",
            "Epoch 60/100 | Train Loss: 3.6056 | Val Loss: 1.5049 | Long: 0.1312 | Lat: 0.8772 | Coverage: 1.0084\n",
            "Epoch 61/100 | Train Loss: 3.6159 | Val Loss: 1.1173 | Long: 0.1370 | Lat: 0.6611 | Coverage: 0.7981\n",
            "Epoch 62/100 | Train Loss: 3.6216 | Val Loss: 1.9937 | Long: 0.1531 | Lat: 1.0703 | Coverage: 1.2234\n",
            "Epoch 63/100 | Train Loss: 3.5983 | Val Loss: 1.6324 | Long: 0.1305 | Lat: 0.9271 | Coverage: 1.0576\n",
            "Epoch 64/100 | Train Loss: 3.6207 | Val Loss: 1.3244 | Long: 0.1603 | Lat: 0.7724 | Coverage: 0.9327\n",
            "Epoch 65/100 | Train Loss: 3.5947 | Val Loss: 1.9678 | Long: 0.1465 | Lat: 1.0616 | Coverage: 1.2081\n",
            "Epoch 66/100 | Train Loss: 3.6080 | Val Loss: 1.6356 | Long: 0.1602 | Lat: 0.9281 | Coverage: 1.0884\n",
            "Epoch 67/100 | Train Loss: 3.6187 | Val Loss: 1.4922 | Long: 0.1368 | Lat: 0.8753 | Coverage: 1.0121\n",
            "Epoch 68/100 | Train Loss: 3.6078 | Val Loss: 1.9800 | Long: 0.1433 | Lat: 1.0843 | Coverage: 1.2276\n",
            "Epoch 69/100 | Train Loss: 3.5890 | Val Loss: 2.0399 | Long: 0.1380 | Lat: 1.1049 | Coverage: 1.2430\n",
            "Epoch 70/100 | Train Loss: 3.5982 | Val Loss: 2.0979 | Long: 0.1462 | Lat: 1.1156 | Coverage: 1.2618\n",
            "Epoch 71/100 | Train Loss: 3.6072 | Val Loss: 1.4219 | Long: 0.1795 | Lat: 0.8187 | Coverage: 0.9982\n",
            "Epoch 72/100 | Train Loss: 3.5889 | Val Loss: 1.2721 | Long: 0.1383 | Lat: 0.7562 | Coverage: 0.8944\n",
            "Epoch 73/100 | Train Loss: 3.6024 | Val Loss: 1.4309 | Long: 0.1409 | Lat: 0.8356 | Coverage: 0.9765\n",
            "Epoch 74/100 | Train Loss: 3.6232 | Val Loss: 1.7590 | Long: 0.1449 | Lat: 0.9820 | Coverage: 1.1269\n",
            "Epoch 75/100 | Train Loss: 3.5621 | Val Loss: 1.5878 | Long: 0.1340 | Lat: 0.9261 | Coverage: 1.0601\n",
            "Epoch 76/100 | Train Loss: 3.5721 | Val Loss: 1.8428 | Long: 0.1593 | Lat: 1.0035 | Coverage: 1.1628\n",
            "Epoch 77/100 | Train Loss: 3.5785 | Val Loss: 2.6601 | Long: 0.1315 | Lat: 1.3226 | Coverage: 1.4540\n",
            "Epoch 78/100 | Train Loss: 3.5839 | Val Loss: 1.7771 | Long: 0.1557 | Lat: 0.9870 | Coverage: 1.1426\n",
            "Epoch 79/100 | Train Loss: 3.6035 | Val Loss: 1.1975 | Long: 0.1553 | Lat: 0.7283 | Coverage: 0.8836\n",
            "Epoch 80/100 | Train Loss: 3.5662 | Val Loss: 2.1861 | Long: 0.1383 | Lat: 1.1803 | Coverage: 1.3186\n",
            "Epoch 81/100 | Train Loss: 3.5678 | Val Loss: 1.2510 | Long: 0.1424 | Lat: 0.7448 | Coverage: 0.8872\n",
            "Epoch 82/100 | Train Loss: 3.5590 | Val Loss: 2.8714 | Long: 0.1396 | Lat: 1.4144 | Coverage: 1.5541\n",
            "Epoch 83/100 | Train Loss: 3.5330 | Val Loss: 2.0680 | Long: 0.1385 | Lat: 1.0932 | Coverage: 1.2317\n",
            "Epoch 84/100 | Train Loss: 3.5378 | Val Loss: 1.3906 | Long: 0.1346 | Lat: 0.8268 | Coverage: 0.9614\n",
            "Epoch 85/100 | Train Loss: 3.5253 | Val Loss: 1.5744 | Long: 0.1564 | Lat: 0.9115 | Coverage: 1.0679\n",
            "Epoch 86/100 | Train Loss: 3.5244 | Val Loss: 1.5517 | Long: 0.1304 | Lat: 0.9094 | Coverage: 1.0398\n",
            "Epoch 87/100 | Train Loss: 3.5450 | Val Loss: 1.4026 | Long: 0.1394 | Lat: 0.8480 | Coverage: 0.9874\n",
            "Epoch 88/100 | Train Loss: 3.5307 | Val Loss: 1.6629 | Long: 0.1539 | Lat: 0.9158 | Coverage: 1.0697\n",
            "Epoch 89/100 | Train Loss: 3.5213 | Val Loss: 1.6331 | Long: 0.1382 | Lat: 0.9376 | Coverage: 1.0758\n",
            "Epoch 90/100 | Train Loss: 3.5541 | Val Loss: 0.9690 | Long: 0.1412 | Lat: 0.6013 | Coverage: 0.7426\n",
            "Epoch 91/100 | Train Loss: 3.5304 | Val Loss: 2.1317 | Long: 0.1510 | Lat: 1.1385 | Coverage: 1.2895\n",
            "Epoch 92/100 | Train Loss: 3.5057 | Val Loss: 1.8518 | Long: 0.1474 | Lat: 1.0175 | Coverage: 1.1649\n",
            "Epoch 93/100 | Train Loss: 3.5145 | Val Loss: 1.2113 | Long: 0.1471 | Lat: 0.7306 | Coverage: 0.8777\n",
            "Epoch 94/100 | Train Loss: 3.5284 | Val Loss: 1.1888 | Long: 0.1344 | Lat: 0.7347 | Coverage: 0.8692\n",
            "Epoch 95/100 | Train Loss: 3.4967 | Val Loss: 3.0212 | Long: 0.1676 | Lat: 1.4424 | Coverage: 1.6100\n",
            "Epoch 96/100 | Train Loss: 3.4990 | Val Loss: 2.2763 | Long: 0.1502 | Lat: 1.1883 | Coverage: 1.3385\n",
            "Epoch 97/100 | Train Loss: 3.5196 | Val Loss: 1.6554 | Long: 0.1833 | Lat: 0.9338 | Coverage: 1.1171\n",
            "Epoch 98/100 | Train Loss: 3.4726 | Val Loss: 1.6852 | Long: 0.1517 | Lat: 0.9632 | Coverage: 1.1149\n",
            "Epoch 99/100 | Train Loss: 3.5255 | Val Loss: 1.9959 | Long: 0.1620 | Lat: 1.0682 | Coverage: 1.2302\n",
            "Epoch 100/100 | Train Loss: 3.5002 | Val Loss: 1.9575 | Long: 0.1484 | Lat: 1.0469 | Coverage: 1.1953\n",
            "Training complete!\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WODRADDO02Hd"
      },
      "source": [
        "## Grader\n",
        "\n",
        "Run the following cell to grade your homework.\n",
        "\n",
        "Note: if you don't set up PySuperTuxKart, the grader will not run the driving tests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ijkV65Bvpaj",
        "outputId": "34e5484a-fd22-4c9e-ccc3-c12951d81b42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Public grader loaded.\n",
            "[DEBUG    00:00:000] Loading assignment\n",
            "[DEBUG    00:00:000] Loading grader\n",
            "[INFO     00:00:002] MLP Planner\n",
            "[DEBUG    00:00:044] Loaded 2000 samples from 4 episodes\n",
            "[INFO     00:00:216]   - Test Output Shape                                  [ 5 / 5 ]\n",
            "[INFO     00:01:407]   - Longitudinal Error                                 [ 10 / 10 ]\n",
            "[WARNING  00:01:407] longitudinal_error: 0.183, required < 0.2\n",
            "[WARNING  00:01:407]   - Longitudinal Error: Extra Credit                   [ 0 / 1 ]\n",
            "[INFO     00:01:408]   - Lateral Error                                      [ 10 / 10 ]\n",
            "[WARNING  00:01:408] lateral_error: 0.577, required < 0.6\n",
            "[WARNING  00:01:408]   - Lateral Error: Extra Credit                        [ 0 / 1 ]\n",
            "[INFO     00:18:009]   - Driving Performance                                [ 10 / 10 ]\n",
            "[WARNING  00:18:009] track coverage: 0.889, required > 0.5\n",
            "[INFO     00:18:009]  --------------------------------------------------    [  35 /  35 ]\n",
            "[INFO     00:18:011] Transformer Planner\n",
            "[DEBUG    00:18:060] Loaded 2000 samples from 4 episodes\n",
            "[INFO     00:18:081]   - Test Output Shape                                  [ 5 / 5 ]\n",
            "[WARNING  00:19:296]   - Longitudinal Error                                 [ 6 / 10 ]\n",
            "[WARNING  00:19:296] longitudinal_error: 0.242, required < 0.2\n",
            "[WARNING  00:19:296]   - Longitudinal Error: Extra Credit                   [ 0 / 1 ]\n",
            "[INFO     00:19:296]   - Lateral Error                                      [ 10 / 10 ]\n",
            "[WARNING  00:19:296] lateral_error: 0.584, required < 0.6\n",
            "[WARNING  00:19:297]   - Lateral Error: Extra Credit                        [ 0 / 1 ]\n",
            "[INFO     00:32:844]   - Driving Performance                                [ 10 / 10 ]\n",
            "[WARNING  00:32:845] track coverage: 0.870, required > 0.5\n",
            "[INFO     00:32:845]  --------------------------------------------------    [  31 /  35 ]\n",
            "[INFO     00:32:847] CNN Planner\n",
            "[DEBUG    00:32:881] Loaded 2000 samples from 4 episodes\n",
            "[INFO     00:33:565]   - Test Output Shape                                  [ 5 / 5 ]\n",
            "[INFO     00:37:028]   - Longitudinal Error                                 [ 10 / 10 ]\n",
            "[WARNING  00:37:028] longitudinal_error: 0.173, required < 0.3\n",
            "[INFO     00:37:028]   - Longitudinal Error: Extra Credit                   [ 1 / 1 ]\n",
            "[INFO     00:37:028]   - Lateral Error                                      [ 10 / 10 ]\n",
            "[WARNING  00:37:028] lateral_error: 0.274, required < 0.45\n",
            "[INFO     00:37:028]   - Lateral Error: Extra Credit                        [ 1 / 1 ]\n",
            "[INFO     00:50:771]   - Driving Performance                                [ 5 / 5 ]\n",
            "[WARNING  00:50:771] track coverage: 0.901, required > 0.5\n",
            "[INFO     00:50:771]  --------------------------------------------------    [  32 /  30 ]\n",
            "[INFO     00:50:771] Total                                                     98 / 100\n"
          ]
        }
      ],
      "source": [
        "!python3 -m grader homework -vv --disable_color"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzPcTJQxvYQR",
        "outputId": "90fb660b-3c0d-42f7-c59a-5704c0aafce8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects:  11% (1/9)\u001b[K\rremote: Counting objects:  22% (2/9)\u001b[K\rremote: Counting objects:  33% (3/9)\u001b[K\rremote: Counting objects:  44% (4/9)\u001b[K\rremote: Counting objects:  55% (5/9)\u001b[K\rremote: Counting objects:  66% (6/9)\u001b[K\rremote: Counting objects:  77% (7/9)\u001b[K\rremote: Counting objects:  88% (8/9)\u001b[K\rremote: Counting objects: 100% (9/9)\u001b[K\rremote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects:  50% (1/2)\u001b[K\rremote: Compressing objects: 100% (2/2)\u001b[K\rremote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 5 (delta 3), reused 5 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects:  20% (1/5)\rUnpacking objects:  40% (2/5)\rUnpacking objects:  60% (3/5)\rUnpacking objects:  80% (4/5)\rUnpacking objects: 100% (5/5)\rUnpacking objects: 100% (5/5), 2.72 KiB | 2.72 MiB/s, done.\n",
            "From https://github.com/chaalp/online_deep_learning\n",
            "   721d4f03..09711a4e  master     -> origin/master\n",
            "Updating 721d4f03..09711a4e\n",
            "Fast-forward\n",
            " homework4/homework/train_transformer_planner.py | 180 \u001b[32m++++++++++++++++++++++++++++++++++++++++\u001b[m\u001b[31m----\u001b[m\n",
            " 1 file changed, 167 insertions(+), 13 deletions(-)\n"
          ]
        }
      ],
      "source": [
        "!git pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiUnZ58P0iZF",
        "outputId": "ae9795c4-fa8a-4d04-d787-957e2eb62db0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34massets\u001b[0m/  bundle.py  \u001b[01;34mdrive_data\u001b[0m/  \u001b[01;34mgrader\u001b[0m/  \u001b[01;34mhomework\u001b[0m/  \u001b[01;34mlogs\u001b[0m/  README.md  requirements.txt\n",
            "On branch master\n",
            "Your branch is up to date with 'origin/master'.\n",
            "\n",
            "Changes not staged for commit:\n",
            "  (use \"git add <file>...\" to update what will be committed)\n",
            "  (use \"git restore <file>...\" to discard changes in working directory)\n",
            "\t\u001b[31mmodified:   grader/__pycache__/__main__.cpython-311.pyc\u001b[m\n",
            "\t\u001b[31mmodified:   grader/__pycache__/grader.cpython-311.pyc\u001b[m\n",
            "\t\u001b[31mmodified:   grader/__pycache__/metrics.cpython-311.pyc\u001b[m\n",
            "\t\u001b[31mmodified:   grader/__pycache__/tests.cpython-311.pyc\u001b[m\n",
            "\t\u001b[31mmodified:   grader/datasets/__pycache__/road_dataset.cpython-311.pyc\u001b[m\n",
            "\t\u001b[31mmodified:   grader/datasets/__pycache__/road_transforms.cpython-311.pyc\u001b[m\n",
            "\t\u001b[31mmodified:   grader/datasets/__pycache__/road_utils.cpython-311.pyc\u001b[m\n",
            "\t\u001b[31mmodified:   grader/supertux_utils/__pycache__/evaluate.cpython-311.pyc\u001b[m\n",
            "\t\u001b[31mmodified:   grader/supertux_utils/__pycache__/video_visualization.cpython-311.pyc\u001b[m\n",
            "\t\u001b[31mmodified:   homework/__pycache__/__init__.cpython-311.pyc\u001b[m\n",
            "\t\u001b[31mmodified:   homework/__pycache__/metrics.cpython-311.pyc\u001b[m\n",
            "\t\u001b[31mmodified:   homework/__pycache__/models.cpython-311.pyc\u001b[m\n",
            "\t\u001b[31mmodified:   homework/__pycache__/train_transformer_planner.cpython-311.pyc\u001b[m\n",
            "\t\u001b[31mmodified:   homework/datasets/__pycache__/road_dataset.cpython-311.pyc\u001b[m\n",
            "\t\u001b[31mmodified:   homework/datasets/__pycache__/road_transforms.cpython-311.pyc\u001b[m\n",
            "\t\u001b[31mmodified:   homework/datasets/__pycache__/road_utils.cpython-311.pyc\u001b[m\n",
            "\t\u001b[31mmodified:   homework/transformer_planner.th\u001b[m\n",
            "\n",
            "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n",
            "[master d82553f2] colab update\n",
            " 17 files changed, 0 insertions(+), 0 deletions(-)\n",
            " rewrite homework4/homework/__pycache__/train_transformer_planner.cpython-311.pyc (84%)\n",
            " rewrite homework4/homework/transformer_planner.th (96%)\n",
            "Enumerating objects: 43, done.\n",
            "Counting objects: 100% (43/43), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (30/30), done.\n",
            "Writing objects: 100% (30/30), 115.94 KiB | 7.25 MiB/s, done.\n",
            "Total 30 (delta 8), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (8/8), completed with 4 local objects.\u001b[K\n",
            "To https://github.com/chaalp/online_deep_learning.git\n",
            "   09711a4e..d82553f2  master -> master\n"
          ]
        }
      ],
      "source": [
        "%ls\n",
        "!git status\n",
        "\n",
        "# Be careful not to \"git add *\" since there are datasets and logs\n",
        "!git add .\n",
        "!git config --global user.email \"chander_alphonse@yahoo.com\"\n",
        "!git config --global user.name \"chaalp\"\n",
        "!git commit -m \"colab update\"\n",
        "!git push"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiCe-RX-J6CF"
      },
      "source": [
        "## Update your changes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxbPtnF55AMU"
      },
      "source": [
        "## Submission\n",
        "\n",
        "Run the following cell to bundle your submission (modify UTID accordingly).\n",
        "\n",
        "If you notice that your bundle is too large, you can modify the `bundle.py` script and ignore large files by adding them manually to `BLACKLIST`.\n",
        "\n",
        "After the bundler and grader run, right click and download your bundled `.zip` file from the Colab UI.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M07WA1Os4Xxh"
      },
      "outputs": [],
      "source": [
        "!python3 bundle.py homework UTID\n",
        "\n",
        "# optional: run the grader with your bundled homework to double check\n",
        "!python3 -m grader UTID.zip -vv --disable_color"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
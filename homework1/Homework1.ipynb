{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gxzo13BN6FL0"
      },
      "source": [
        "## Code Setup\n",
        "\n",
        "Move into `homework1/`.\n",
        "\n",
        "This will be the main working directory and the training/grading must be run from this directory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "et3KFSXs3IHk",
        "outputId": "2f802a64-f150-4328-abda-6121480bf573"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/advances_in_deep_learning\n",
            "\u001b[0m\u001b[01;34mhomework1\u001b[0m/  \u001b[01;34mhomework2\u001b[0m/  \u001b[01;34mhomework3\u001b[0m/  \u001b[01;34mhomework4\u001b[0m/\n",
            "/content/advances_in_deep_learning/homework1\n",
            "bignet.pth  \u001b[0m\u001b[01;34mgrader\u001b[0m/    Homework1.ipynb  requirements.txt\n",
            "bundle.py   \u001b[01;34mhomework\u001b[0m/  README.md\n"
          ]
        }
      ],
      "source": [
        "# navigate to your repo\n",
        "%cd /content/{os.environ['REPO']}\n",
        "%ls\n",
        "\n",
        "# go to a specific homework\n",
        "%cd homework1\n",
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "id": "zLy_5AIgF62F",
        "outputId": "79eb7dc2-313c-4084-8f0b-b67cb5f5b0be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects:  11% (1/9)\u001b[K\rremote: Counting objects:  22% (2/9)\u001b[K\rremote: Counting objects:  33% (3/9)\u001b[K\rremote: Counting objects:  44% (4/9)\u001b[K\rremote: Counting objects:  55% (5/9)\u001b[K\rremote: Counting objects:  66% (6/9)\u001b[K\rremote: Counting objects:  77% (7/9)\u001b[K\rremote: Counting objects:  88% (8/9)\u001b[K\rremote: Counting objects: 100% (9/9)\u001b[K\rremote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects:  50% (1/2)\u001b[K\rremote: Compressing objects: 100% (2/2)\u001b[K\rremote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 5 (delta 3), reused 5 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects:  20% (1/5)\rUnpacking objects:  40% (2/5)\rUnpacking objects:  60% (3/5)\rUnpacking objects:  80% (4/5)\rUnpacking objects: 100% (5/5)\rUnpacking objects: 100% (5/5), 1.07 KiB | 1.07 MiB/s, done.\n",
            "From https://github.com/chaalp/advances_in_deep_learning\n",
            "   79dbc1d..29f4a1e  main       -> origin/main\n",
            "Updating 79dbc1d..29f4a1e\n",
            "Fast-forward\n",
            " homework1/homework/lora.py | 58 \u001b[32m+++++++++++++++++++++++++++++++++++++++++\u001b[m\u001b[31m-----\u001b[m\n",
            " 1 file changed, 52 insertions(+), 6 deletions(-)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Q4sbuDqn3tq",
        "outputId": "434bd2f5-61f6-4259-877a-834c2732aae9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch>=2.4.1 in /usr/local/lib/python3.12/dist-packages (from -r ./requirements.txt (line 1)) (2.9.0+cu126)\n",
            "Requirement already satisfied: numpy>=2.2.1 in /usr/local/lib/python3.12/dist-packages (from -r ./requirements.txt (line 2)) (2.4.1)\n",
            "Requirement already satisfied: termcolor>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from -r ./requirements.txt (line 3)) (3.3.0)\n",
            "Requirement already satisfied: fire>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from -r ./requirements.txt (line 4)) (0.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->-r ./requirements.txt (line 1)) (3.20.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->-r ./requirements.txt (line 1)) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->-r ./requirements.txt (line 1)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->-r ./requirements.txt (line 1)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->-r ./requirements.txt (line 1)) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->-r ./requirements.txt (line 1)) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->-r ./requirements.txt (line 1)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->-r ./requirements.txt (line 1)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->-r ./requirements.txt (line 1)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->-r ./requirements.txt (line 1)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->-r ./requirements.txt (line 1)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->-r ./requirements.txt (line 1)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->-r ./requirements.txt (line 1)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->-r ./requirements.txt (line 1)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->-r ./requirements.txt (line 1)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->-r ./requirements.txt (line 1)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->-r ./requirements.txt (line 1)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->-r ./requirements.txt (line 1)) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->-r ./requirements.txt (line 1)) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->-r ./requirements.txt (line 1)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->-r ./requirements.txt (line 1)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->-r ./requirements.txt (line 1)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->-r ./requirements.txt (line 1)) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.4.1->-r ./requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.4.1->-r ./requirements.txt (line 1)) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r ./requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLe2Ti0xJeIL",
        "outputId": "43735c0a-a4af-4469-a65a-bff5ce23c4ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                         bignet    \n",
            "Trainable params          18.90 M  \n",
            "Non-trainable params       0.00 M  \n",
            "Total params              18.90 M  \n",
            "Theoretical memory        72.11 MB \n",
            "Actual memory             72.11 MB \n",
            "Forward memory             9.12 MB \n",
            "Backward memory           80.23 MB \n"
          ]
        }
      ],
      "source": [
        "!python3 -m homework.stats bignet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m homework.stats bignet half_precision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvfc-tviCAiT",
        "outputId": "48f07845-ccf1-486f-fa10-ce03b65de87d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                         bignet     half_precision\n",
            "Trainable params          18.90 M         0.01 M  \n",
            "Non-trainable params       0.00 M        18.89 M  \n",
            "Total params              18.90 M        18.90 M  \n",
            "Theoretical memory        72.11 MB       36.07 MB \n",
            "Actual memory             72.11 MB       36.07 MB \n",
            "Forward memory             9.12 MB        0.00 MB \n",
            "Backward memory           80.23 MB        0.04 MB \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m homework.compare bignet half_precision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMdH1QLi7kgW",
        "outputId": "f6d373ba-5e9a-4073-dab4-0fe4e69d4fac"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparing bignet and half_precision\n",
            " - Max difference: 0.0016\n",
            " - Mean difference: 0.0002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m homework.stats bignet lora"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ilcx-LSt7tye",
        "outputId": "67e0e594-7183-4acc-daae-70fc5c4f62d8"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                         bignet          lora     \n",
            "Trainable params          18.90 M         1.19 M  \n",
            "Non-trainable params       0.00 M        18.89 M  \n",
            "Total params              18.90 M        20.08 M  \n",
            "Theoretical memory        72.11 MB       40.57 MB \n",
            "Actual memory             72.11 MB       40.57 MB \n",
            "Forward memory             9.12 MB        0.00 MB \n",
            "Backward memory           80.23 MB        4.54 MB \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m homework.compare bignet lora"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dG-cTCo5744E",
        "outputId": "d98bc245-896c-4c4f-c33d-6b5eebea9b8a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparing bignet and lora\n",
            " - Max difference: 0.0014\n",
            " - Mean difference: 0.0002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m homework.fit lora"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lki31SFq8D6r",
        "outputId": "016268c4-6937-4f57-f20a-7b5613be4c34"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss = 0.7343, Accuracy = 0.5210\n",
            "Epoch 2: Loss = 0.7201, Accuracy = 0.4990\n",
            "Epoch 3: Loss = 0.7244, Accuracy = 0.5300\n",
            "Epoch 4: Loss = 0.7001, Accuracy = 0.5230\n",
            "Epoch 5: Loss = 0.7001, Accuracy = 0.5270\n",
            "Epoch 6: Loss = 0.6777, Accuracy = 0.5610\n",
            "Epoch 7: Loss = 0.6699, Accuracy = 0.5960\n",
            "Epoch 8: Loss = 0.6482, Accuracy = 0.6310\n",
            "Epoch 9: Loss = 0.6229, Accuracy = 0.6680\n",
            "Epoch 10: Loss = 0.5984, Accuracy = 0.6870\n",
            "Epoch 11: Loss = 0.5524, Accuracy = 0.7810\n",
            "Epoch 12: Loss = 0.5113, Accuracy = 0.7940\n",
            "Epoch 13: Loss = 0.4479, Accuracy = 0.8220\n",
            "Epoch 14: Loss = 0.3786, Accuracy = 0.8640\n",
            "Epoch 15: Loss = 0.3547, Accuracy = 0.8420\n",
            "Epoch 16: Loss = 0.3720, Accuracy = 0.8500\n",
            "Epoch 17: Loss = 0.2997, Accuracy = 0.8820\n",
            "Epoch 18: Loss = 0.2805, Accuracy = 0.8800\n",
            "Epoch 19: Loss = 0.2236, Accuracy = 0.9170\n",
            "Epoch 20: Loss = 0.1921, Accuracy = 0.9270\n",
            "Epoch 21: Loss = 0.1575, Accuracy = 0.9550\n",
            "Epoch 22: Loss = 0.1410, Accuracy = 0.9650\n",
            "Epoch 23: Loss = 0.1061, Accuracy = 0.9770\n",
            "Epoch 24: Loss = 0.0950, Accuracy = 0.9760\n",
            "Epoch 25: Loss = 0.0572, Accuracy = 0.9930\n",
            "Epoch 26: Loss = 0.0510, Accuracy = 0.9870\n",
            "Epoch 27: Loss = 0.0236, Accuracy = 0.9960\n",
            "Epoch 28: Loss = 0.0221, Accuracy = 0.9950\n",
            "Epoch 29: Loss = 0.0116, Accuracy = 0.9990\n",
            "Epoch 30: Loss = 0.0112, Accuracy = 0.9990\n",
            "Epoch 31: Loss = 0.0112, Accuracy = 0.9990\n",
            "Epoch 32: Loss = 0.0107, Accuracy = 0.9990\n",
            "Epoch 33: Loss = 0.0102, Accuracy = 0.9990\n",
            "Epoch 34: Loss = 0.0099, Accuracy = 0.9990\n",
            "Epoch 35: Loss = 0.0094, Accuracy = 0.9990\n",
            "Epoch 36: Loss = 0.0089, Accuracy = 0.9990\n",
            "Epoch 37: Loss = 0.0081, Accuracy = 0.9990\n",
            "Epoch 38: Loss = 0.0070, Accuracy = 0.9990\n",
            "Epoch 39: Loss = 0.0048, Accuracy = 0.9990\n",
            "Epoch 40: Loss = 0.0004, Accuracy = 1.0000\n",
            "Epoch 41: Loss = 0.0007, Accuracy = 1.0000\n",
            "Epoch 42: Loss = 0.0015, Accuracy = 1.0000\n",
            "Epoch 43: Loss = 0.0423, Accuracy = 0.9920\n",
            "Epoch 44: Loss = 0.3836, Accuracy = 0.9300\n",
            "Epoch 45: Loss = 0.1385, Accuracy = 0.9640\n",
            "Epoch 46: Loss = 0.1479, Accuracy = 0.9860\n",
            "Epoch 47: Loss = 0.0897, Accuracy = 0.9820\n",
            "Epoch 48: Loss = 0.0267, Accuracy = 0.9940\n",
            "Epoch 49: Loss = 0.0605, Accuracy = 0.9790\n",
            "Epoch 50: Loss = 0.0552, Accuracy = 0.9770\n",
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m homework.stats bignet low_precision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_RO_sdd8V1p",
        "outputId": "62fd4748-4435-4de6-c394-21c3c2939b6c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/content/advances_in_deep_learning/homework1/homework/stats.py\", line 168, in <module>\n",
            "    Fire(model_info)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fire/core.py\", line 135, in Fire\n",
            "    component_trace = _Fire(component, args, parsed_flag_args, context, name)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fire/core.py\", line 468, in _Fire\n",
            "    component, remaining_args = _CallAndUpdateTrace(\n",
            "                                ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fire/core.py\", line 684, in _CallAndUpdateTrace\n",
            "    component = fn(*varargs, **kwargs)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/advances_in_deep_learning/homework1/homework/stats.py\", line 149, in model_info\n",
            "    model = load_model(model_name, None)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/advances_in_deep_learning/homework1/homework/stats.py\", line 23, in load_model\n",
            "    return ALL_MODELS[model_name].load(path)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/advances_in_deep_learning/homework1/homework/low_precision.py\", line 113, in load\n",
            "    net = BigNet4Bit()\n",
            "          ^^^^^^^^^^^^\n",
            "  File \"/content/advances_in_deep_learning/homework1/homework/low_precision.py\", line 106, in __init__\n",
            "    raise NotImplementedError()\n",
            "NotImplementedError\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WODRADDO02Hd"
      },
      "source": [
        "## Grader\n",
        "\n",
        "Run the following cell to grade your homework.\n",
        "\n",
        "Note: if you don't set up PySuperTuxKart, the grader will not run the driving tests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ijkV65Bvpaj",
        "outputId": "4509bee2-15c6-45e1-9f3b-c6da7f5e6a46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val grader loaded.\n",
            "[DEBUG    00:00:000] Loading assignment\n",
            "[DEBUG    00:00:001] Loading grader\n",
            "[INFO     00:00:002] LoRA\n",
            "[WARNING  00:00:869]   - Forward accuracy                                   [ 10 / 10  ]\n",
            "[WARNING  00:01:181]   - Memory and parameters                              [ 10 / 10  ]\n",
            "[DEBUG    00:02:450] Epoch 1: Loss = 0.7761, Accuracy = 0.5020\n",
            "[DEBUG    00:02:471] Epoch 2: Loss = 0.7110, Accuracy = 0.4980\n",
            "[DEBUG    00:02:492] Epoch 3: Loss = 0.8781, Accuracy = 0.4990\n",
            "[DEBUG    00:02:513] Epoch 4: Loss = 0.6969, Accuracy = 0.5550\n",
            "[DEBUG    00:02:534] Epoch 5: Loss = 0.7192, Accuracy = 0.5250\n",
            "[DEBUG    00:02:554] Epoch 6: Loss = 0.7322, Accuracy = 0.5230\n",
            "[DEBUG    00:02:571] Epoch 7: Loss = 0.7013, Accuracy = 0.5450\n",
            "[DEBUG    00:02:588] Epoch 8: Loss = 0.6714, Accuracy = 0.5800\n",
            "[DEBUG    00:02:605] Epoch 9: Loss = 0.6894, Accuracy = 0.5610\n",
            "[DEBUG    00:02:623] Epoch 10: Loss = 0.6800, Accuracy = 0.5710\n",
            "[DEBUG    00:02:640] Epoch 11: Loss = 0.6329, Accuracy = 0.6460\n",
            "[DEBUG    00:02:657] Epoch 12: Loss = 0.6047, Accuracy = 0.6820\n",
            "[DEBUG    00:02:674] Epoch 13: Loss = 0.5950, Accuracy = 0.6830\n",
            "[DEBUG    00:02:692] Epoch 14: Loss = 0.5695, Accuracy = 0.7060\n",
            "[DEBUG    00:02:712] Epoch 15: Loss = 0.5182, Accuracy = 0.7870\n",
            "[DEBUG    00:02:729] Epoch 16: Loss = 0.4670, Accuracy = 0.8320\n",
            "[DEBUG    00:02:746] Epoch 17: Loss = 0.4370, Accuracy = 0.8180\n",
            "[DEBUG    00:02:761] Epoch 18: Loss = 0.3837, Accuracy = 0.8440\n",
            "[DEBUG    00:02:774] Epoch 19: Loss = 0.3185, Accuracy = 0.8700\n",
            "[DEBUG    00:02:788] Epoch 20: Loss = 0.3012, Accuracy = 0.8810\n",
            "[WARNING  00:02:789]   - Backward accuracy                                  [ 10 / 10  ]\n",
            "[INFO     00:02:789]  --------------------------------------------------    [  30 /  30 ]\n",
            "[INFO     00:02:789] QLORA\n",
            "[WARNING  00:03:002]   - Forward accuracy                                   [ 0 / 10 Not Implemented ]\n",
            "[WARNING  00:03:002]   - Memory and parameters                              [ 0 / 10 Not Implemented ]\n",
            "[WARNING  00:03:002]   - Backward accuracy                                  [ 0 / 10 Not Implemented ]\n",
            "[INFO     00:03:002]  --------------------------------------------------    [   0 /  30 ]\n",
            "[INFO     00:03:003] Half Precision\n",
            "[WARNING  00:03:412]   - Forward accuracy                                   [ 10 / 10  ]\n",
            "[WARNING  00:03:640]   - Memory and parameters                              [ 10 / 10  ]\n",
            "[INFO     00:03:640]  --------------------------------------------------    [  20 /  20 ]\n",
            "[INFO     00:03:641] Low Precision\n",
            "[WARNING  00:03:855]   - Forward accuracy                                   [ 0 / 10 Not Implemented ]\n",
            "[WARNING  00:03:855]   - Memory and parameters                              [ 0 / 10 Not Implemented ]\n",
            "[INFO     00:03:855]  --------------------------------------------------    [   0 /  20 ]\n",
            "[INFO     00:03:855] Lower Precision\n",
            "[WARNING  00:03:856]   - Extra Credit                                       [ 0 / 5 AttributeError ]\n",
            "[ERROR    00:03:856] Traceback (most recent call last):\n",
            "  File \"/content/advances_in_deep_learning/homework1/grader/grader.py\", line 64, in wrapper\n",
            "    v = func(self, **a)\n",
            "        ^^^^^^^^^^^^^^^\n",
            "  File \"/content/advances_in_deep_learning/homework1/grader/tests.py\", line 334, in test_forward_diff\n",
            "    lower_model = self.load_model(\"lower_precision\").to(self.device)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'NoneType' object has no attribute 'to'\n",
            "[INFO     00:03:856]  --------------------------------------------------    [   0 /   0 ]\n",
            "[INFO     00:03:856] Total                                                     50 / 100\n"
          ]
        }
      ],
      "source": [
        "!python3 -m grader homework -vv --disable_color"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzPcTJQxvYQR",
        "outputId": "840ce775-9b8d-4e88-8dfc-d72e05d59f11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects:  11% (1/9)\u001b[K\rremote: Counting objects:  22% (2/9)\u001b[K\rremote: Counting objects:  33% (3/9)\u001b[K\rremote: Counting objects:  44% (4/9)\u001b[K\rremote: Counting objects:  55% (5/9)\u001b[K\rremote: Counting objects:  66% (6/9)\u001b[K\rremote: Counting objects:  77% (7/9)\u001b[K\rremote: Counting objects:  88% (8/9)\u001b[K\rremote: Counting objects: 100% (9/9)\u001b[K\rremote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects:  50% (1/2)\u001b[K\rremote: Compressing objects: 100% (2/2)\u001b[K\rremote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 5 (delta 3), reused 5 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects:  20% (1/5)\rUnpacking objects:  40% (2/5)\rUnpacking objects:  60% (3/5)\rUnpacking objects:  80% (4/5)\rUnpacking objects: 100% (5/5)\rUnpacking objects: 100% (5/5), 533 bytes | 533.00 KiB/s, done.\n",
            "From https://github.com/chaalp/advances_in_deep_learning\n",
            "   23df16f..79dbc1d  main       -> origin/main\n",
            "Updating 23df16f..79dbc1d\n",
            "Fast-forward\n",
            " homework1/homework/half_precision.py | 42 \u001b[32m+++++++++++++++\u001b[m\u001b[31m---------------------\u001b[m\n",
            " 1 file changed, 17 insertions(+), 25 deletions(-)\n"
          ]
        }
      ],
      "source": [
        "%ls\n",
        "!git status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiUnZ58P0iZF",
        "outputId": "7b0d4d8f-b42b-44a7-9ba6-3c056bb3512d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bignet.pth  \u001b[0m\u001b[01;34mgrader\u001b[0m/    Homework1.ipynb  requirements.txt\n",
            "bundle.py   \u001b[01;34mhomework\u001b[0m/  README.md\n",
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "nothing to commit, working tree clean\n",
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "nothing to commit, working tree clean\n",
            "Everything up-to-date\n"
          ]
        }
      ],
      "source": [
        "# Be careful not to \"git add *\" since there are datasets and logs\n",
        "!git add .\n",
        "!git config --global user.email \"chander_alphonse@yahoo.com\"\n",
        "!git config --global user.name \"chaalp\"\n",
        "!git commit -m \"colab update\"\n",
        "!git push"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiCe-RX-J6CF"
      },
      "source": [
        "## Update your changes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxbPtnF55AMU"
      },
      "source": [
        "## Submission\n",
        "\n",
        "Run the following cell to bundle your submission (modify UTID accordingly).\n",
        "\n",
        "If you notice that your bundle is too large, you can modify the `bundle.py` script and ignore large files by adding them manually to `BLACKLIST`.\n",
        "\n",
        "After the bundler and grader run, right click and download your bundled `.zip` file from the Colab UI.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M07WA1Os4Xxh"
      },
      "outputs": [],
      "source": [
        "!python3 bundle.py homework UTID\n",
        "\n",
        "# optional: run the grader with your bundled homework to double check\n",
        "!python3 -m grader UTID.zip -vv --disable_color"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gxzo13BN6FL0"
      },
      "source": [
        "## Code Setup\n",
        "\n",
        "Move into `homework3/`.\n",
        "\n",
        "This will be the main working directory and the training/grading must be run from this directory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "et3KFSXs3IHk",
        "outputId": "e2892abb-adb1-4b79-a63e-6ddc303a9f89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/advances_in_deep_learning\n",
            "\u001b[0m\u001b[01;34mhomework1\u001b[0m/  \u001b[01;34mhomework2\u001b[0m/  \u001b[01;34mhomework3\u001b[0m/  \u001b[01;34mhomework4\u001b[0m/\n",
            "/content/advances_in_deep_learning/homework3\n",
            "bundle.py  \u001b[0m\u001b[01;34mgrader\u001b[0m/    Homework3.ipynb  requirements.txt\n",
            "\u001b[01;34mdata\u001b[0m/      \u001b[01;34mhomework\u001b[0m/  README.md\n"
          ]
        }
      ],
      "source": [
        "# navigate to your repo\n",
        "%cd /content/advances_in_deep_learning\n",
        "%ls\n",
        "\n",
        "# go to a specific homework\n",
        "%cd homework3\n",
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLy_5AIgF62F",
        "outputId": "92b3528a-8d7c-472c-8155-25c0759f8b72"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Q4sbuDqn3tq",
        "outputId": "1982715e-304f-4dd3-be75-0d89ee9c9edd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fire>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from -r ./requirements.txt (line 1)) (0.7.1)\n",
            "Requirement already satisfied: lightning>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from -r ./requirements.txt (line 2)) (2.6.0)\n",
            "Requirement already satisfied: torch>=2.6.0 in /usr/local/lib/python3.12/dist-packages (from -r ./requirements.txt (line 3)) (2.9.0+cu126)\n",
            "Requirement already satisfied: transformers==4.52.4 in /usr/local/lib/python3.12/dist-packages (from -r ./requirements.txt (line 4)) (4.52.4)\n",
            "Requirement already satisfied: numpy>=2.2.1 in /usr/local/lib/python3.12/dist-packages (from -r ./requirements.txt (line 5)) (2.4.1)\n",
            "Requirement already satisfied: Pillow>=11.1.0 in /usr/local/lib/python3.12/dist-packages (from -r ./requirements.txt (line 6)) (11.3.0)\n",
            "Requirement already satisfied: tqdm>=4.66.0 in /usr/local/lib/python3.12/dist-packages (from -r ./requirements.txt (line 7)) (4.67.1)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.12/dist-packages (from -r ./requirements.txt (line 8)) (1.12.0)\n",
            "Requirement already satisfied: tensorboard>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from -r ./requirements.txt (line 9)) (2.19.0)\n",
            "Requirement already satisfied: peft>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from -r ./requirements.txt (line 10)) (0.18.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.52.4->-r ./requirements.txt (line 4)) (3.20.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.52.4->-r ./requirements.txt (line 4)) (0.36.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.52.4->-r ./requirements.txt (line 4)) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.52.4->-r ./requirements.txt (line 4)) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.52.4->-r ./requirements.txt (line 4)) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.52.4->-r ./requirements.txt (line 4)) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers==4.52.4->-r ./requirements.txt (line 4)) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers==4.52.4->-r ./requirements.txt (line 4)) (0.7.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from fire>=0.7.0->-r ./requirements.txt (line 1)) (3.3.0)\n",
            "Requirement already satisfied: fsspec<2027.0,>=2022.5.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning>=2.5.0->-r ./requirements.txt (line 2)) (2025.3.0)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from lightning>=2.5.0->-r ./requirements.txt (line 2)) (0.15.2)\n",
            "Requirement already satisfied: torchmetrics<3.0,>0.7.0 in /usr/local/lib/python3.12/dist-packages (from lightning>=2.5.0->-r ./requirements.txt (line 2)) (1.8.2)\n",
            "Requirement already satisfied: typing-extensions<6.0,>4.5.0 in /usr/local/lib/python3.12/dist-packages (from lightning>=2.5.0->-r ./requirements.txt (line 2)) (4.15.0)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.12/dist-packages (from lightning>=2.5.0->-r ./requirements.txt (line 2)) (2.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.6.0->-r ./requirements.txt (line 3)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6.0->-r ./requirements.txt (line 3)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6.0->-r ./requirements.txt (line 3)) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6.0->-r ./requirements.txt (line 3)) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6.0->-r ./requirements.txt (line 3)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6.0->-r ./requirements.txt (line 3)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6.0->-r ./requirements.txt (line 3)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6.0->-r ./requirements.txt (line 3)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6.0->-r ./requirements.txt (line 3)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6.0->-r ./requirements.txt (line 3)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6.0->-r ./requirements.txt (line 3)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6.0->-r ./requirements.txt (line 3)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6.0->-r ./requirements.txt (line 3)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6.0->-r ./requirements.txt (line 3)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6.0->-r ./requirements.txt (line 3)) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6.0->-r ./requirements.txt (line 3)) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6.0->-r ./requirements.txt (line 3)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6.0->-r ./requirements.txt (line 3)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6.0->-r ./requirements.txt (line 3)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6.0->-r ./requirements.txt (line 3)) (3.5.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.26.0->-r ./requirements.txt (line 8)) (5.9.5)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.15.0->-r ./requirements.txt (line 9)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.15.0->-r ./requirements.txt (line 9)) (1.76.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.15.0->-r ./requirements.txt (line 9)) (3.10)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.15.0->-r ./requirements.txt (line 9)) (5.29.5)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.15.0->-r ./requirements.txt (line 9)) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.15.0->-r ./requirements.txt (line 9)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.15.0->-r ./requirements.txt (line 9)) (3.1.5)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning>=2.5.0->-r ./requirements.txt (line 2)) (3.13.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.4->-r ./requirements.txt (line 4)) (1.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.6.0->-r ./requirements.txt (line 3)) (1.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.15.0->-r ./requirements.txt (line 9)) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.52.4->-r ./requirements.txt (line 4)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.52.4->-r ./requirements.txt (line 4)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.52.4->-r ./requirements.txt (line 4)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.52.4->-r ./requirements.txt (line 4)) (2026.1.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.5.0->-r ./requirements.txt (line 2)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.5.0->-r ./requirements.txt (line 2)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.5.0->-r ./requirements.txt (line 2)) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.5.0->-r ./requirements.txt (line 2)) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.5.0->-r ./requirements.txt (line 2)) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.5.0->-r ./requirements.txt (line 2)) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.5.0->-r ./requirements.txt (line 2)) (1.22.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r ./requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"PYTORCH_ALLOC_CONF\"] = \"expandable_segments:True\""
      ],
      "metadata": {
        "id": "1RHddFeIrV-w"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m homework.base_llm test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHp2gIug-Xgz",
        "outputId": "852d4f31-7feb-4f35-a50a-078c63014483"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<frozen runpy>:128: RuntimeWarning: 'homework.base_llm' found in sys.modules after import of package 'homework', but prior to execution of 'homework.base_llm'; this may result in unpredictable behaviour\n",
            "tokenizer_config.json: 3.76kB [00:00, 19.6MB/s]\n",
            "vocab.json: 801kB [00:00, 55.2MB/s]\n",
            "merges.txt: 466kB [00:00, 123MB/s]\n",
            "tokenizer.json: 2.10MB [00:00, 173MB/s]\n",
            "special_tokens_map.json: 100% 655/655 [00:00<00:00, 3.07MB/s]\n",
            "config.json: 100% 846/846 [00:00<00:00, 6.64MB/s]\n",
            "2026-01-27 02:43:22.750746: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769481802.767217     945 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769481802.772077     945 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769481802.785764     945 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769481802.785790     945 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769481802.785794     945 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769481802.785799     945 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-27 02:43:22.790124: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "model.safetensors: 100% 724M/724M [00:04<00:00, 167MB/s]\n",
            "generation_config.json: 100% 132/132 [00:00<00:00, 1.39MB/s]\n",
            "testing generate function\n",
            "input The cat went up\n",
            "output  the stairs, and the cat went up the stairs, and the cat went up the stairs, and the cat went up the stairs, and the cat went up the stairs, and the cat went up the stairs, and the cat went up the stairs, and the cat went up the stairs, and the cat went up\n",
            "testing generate function\n",
            "input The dog went down\n",
            "output  the stairs and into the basement.\n",
            "\n",
            "The dog went down the stairs and into the basement.\n",
            "\n",
            "Which sentence is correct?\n",
            "[' the stairs, and the cat went up the stairs, and the cat went up the stairs, and the cat went up the stairs, and the cat went up the stairs, and the cat went up the stairs, and the cat went up the stairs, and the cat went up the stairs, and the cat went up', ' the stairs and into the basement.\\n\\nThe dog went down the stairs and into the basement.\\n\\nWhich sentence is correct?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLe2Ti0xJeIL",
        "outputId": "4effeb22-f260-4793-fa0c-bc9e0f07fb10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "!git pull"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m homework.cot test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvfc-tviCAiT",
        "outputId": "908790ca-ad68-44d0-d083-9ac6e9cfa1e6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<frozen runpy>:128: RuntimeWarning: 'homework.cot' found in sys.modules after import of package 'homework', but prior to execution of 'homework.cot'; this may result in unpredictable behaviour\n",
            "2026-01-27 02:44:41.865534: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769481881.884656    1370 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769481881.890509    1370 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769481881.905247    1370 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769481881.905274    1370 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769481881.905278    1370 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769481881.905283    1370 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-27 02:44:41.909730: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "benchmark_result.accuracy=0.52  benchmark_result.answer_rate=1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "id": "SahCpmkgxlft",
        "outputId": "4e7aa18a-d73e-44f3-cddf-ec65c95d4b75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m homework.sft train --output_dir homework/sft_model --learning_rate 5e-5 --num_train_epochs 5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ilcx-LSt7tye",
        "outputId": "2590555d-5067-479d-95ce-dad9e7b3cbb5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<frozen runpy>:128: RuntimeWarning: 'homework.sft' found in sys.modules after import of package 'homework', but prior to execution of 'homework.sft'; this may result in unpredictable behaviour\n",
            "2026-01-27 02:45:17.301821: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769481917.320994    1542 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769481917.327031    1542 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769481917.341715    1542 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769481917.341744    1542 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769481917.341748    1542 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769481917.341754    1542 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-27 02:45:17.346235: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "trainable params: 8,683,520 || all params: 370,504,640 || trainable%: 2.3437\n",
            "{'loss': 1.3835, 'grad_norm': 1.017758846282959, 'learning_rate': 9.560439560439561e-05, 'epoch': 0.31}\n",
            "{'loss': 0.8642, 'grad_norm': 0.44801342487335205, 'learning_rate': 8.461538461538461e-05, 'epoch': 0.62}\n",
            "{'loss': 0.7213, 'grad_norm': 0.4048152267932892, 'learning_rate': 7.362637362637363e-05, 'epoch': 0.94}\n",
            "{'loss': 0.6859, 'grad_norm': 0.3572535812854767, 'learning_rate': 6.263736263736263e-05, 'epoch': 1.25}\n",
            "{'loss': 0.6067, 'grad_norm': 0.39872047305107117, 'learning_rate': 5.164835164835166e-05, 'epoch': 1.56}\n",
            "{'loss': 0.563, 'grad_norm': 0.4463897943496704, 'learning_rate': 4.065934065934066e-05, 'epoch': 1.88}\n",
            "{'loss': 0.5121, 'grad_norm': 0.35771480202674866, 'learning_rate': 2.9670329670329673e-05, 'epoch': 2.19}\n",
            "{'loss': 0.4984, 'grad_norm': 0.40742453932762146, 'learning_rate': 1.8681318681318682e-05, 'epoch': 2.5}\n",
            "{'loss': 0.5386, 'grad_norm': 0.4634726643562317, 'learning_rate': 7.692307692307694e-06, 'epoch': 2.81}\n",
            "{'train_runtime': 896.2459, 'train_samples_per_second': 3.347, 'train_steps_per_second': 0.107, 'train_loss': 0.6976573616266251, 'epoch': 3.0}\n",
            "100% 96/96 [14:56<00:00,  9.34s/it]\n",
            "benchmark_result.accuracy=0.43  benchmark_result.answer_rate=1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from homework.sft import load\n",
        "llm = load()\n",
        "\n",
        "test_q = \"How many meters are in 2 kilometers?\"\n",
        "raw_output = llm.generate(test_q)\n",
        "\n",
        "print(f\"PROMPT SENT: {llm.format_prompt(test_q)}\")\n",
        "print(f\"RAW MODEL OUTPUT: '{raw_output}'\")\n",
        "print(f\"PARSED ANSWER: {llm.parse_answer(raw_output)}\")\n",
        "\n",
        "raw_out = llm.batched_generate([llm.format_prompt(test_q)], temperature=0.5)\n",
        "print(f\"Randomized output: '{raw_out[0]}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3N6woXVvzuZ",
        "outputId": "73f466cf-107f-435b-fc96-20c8a032ee7f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PROMPT SENT: <|im_start|>system\n",
            "You are a helpful assistant that performs unit conversions. Show brief reasoning, then provide the final numeric result inside <answer> tags.<|im_end|>\n",
            "<|im_start|>user\n",
            "How many meters are there in 6 km?<|im_end|>\n",
            "<|im_start|>assistant\n",
            "1 km = 1000 m, so 6 * 1000 = 6000. <answer>6000</answer><|im_end|>\n",
            "<|im_start|>user\n",
            "Convert 2.5 inches to centimeters.<|im_end|>\n",
            "<|im_start|>assistant\n",
            "1 inch is 2.54 cm. 2.5 * 2.54 = 6.35. <answer>6.35</answer><|im_end|>\n",
            "<|im_start|>user\n",
            "How many meters are in 2 kilometers? Answer with <answer>...</answer>.<|im_end|>\n",
            "<|im_start|>assistant\n",
            "\n",
            "RAW MODEL OUTPUT: '\n",
            "\n",
            "The answer is:'\n",
            "PARSED ANSWER: nan\n",
            "Randomized output: '<answer>2000</answer>'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m homework.sft test --ckpt_path homework/sft_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dG-cTCo5744E",
        "outputId": "d72037b7-fb03-41d3-ed20-49e7f8d230b0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<frozen runpy>:128: RuntimeWarning: 'homework.sft' found in sys.modules after import of package 'homework', but prior to execution of 'homework.sft'; this may result in unpredictable behaviour\n",
            "2026-01-27 03:03:22.964634: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769483002.983880    6022 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769483002.989924    6022 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769483003.004982    6022 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769483003.005014    6022 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769483003.005030    6022 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769483003.005034    6022 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "benchmark_result.accuracy=0.43  benchmark_result.answer_rate=1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "id": "6dtWHDvn0uNG",
        "outputId": "2eb59dd1-4edb-4343-b6f4-a3b83ab09aca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects:  11% (1/9)\u001b[K\rremote: Counting objects:  22% (2/9)\u001b[K\rremote: Counting objects:  33% (3/9)\u001b[K\rremote: Counting objects:  44% (4/9)\u001b[K\rremote: Counting objects:  55% (5/9)\u001b[K\rremote: Counting objects:  66% (6/9)\u001b[K\rremote: Counting objects:  77% (7/9)\u001b[K\rremote: Counting objects:  88% (8/9)\u001b[K\rremote: Counting objects: 100% (9/9)\u001b[K\rremote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1)\u001b[K\rremote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 5 (delta 4), reused 5 (delta 4), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects:  20% (1/5)\rUnpacking objects:  40% (2/5)\rUnpacking objects:  60% (3/5)\rUnpacking objects:  80% (4/5)\rUnpacking objects: 100% (5/5)\rUnpacking objects: 100% (5/5), 391 bytes | 391.00 KiB/s, done.\n",
            "From https://github.com/chaalp/advances_in_deep_learning\n",
            "   964e476..916366d  main       -> origin/main\n",
            "Updating 964e476..916366d\n",
            "Fast-forward\n",
            " homework3/homework/datagen.py | 2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m homework.datagen --output_json data/rft.json --oversample 10 --temperature 0.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5d3da24-ce1c-41b4-c538-0889d24a53be",
        "id": "cPO6p_U2rsOz"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-01-26 19:30:32.110370: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769455832.129988   14037 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769455832.135883   14037 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769455832.151775   14037 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769455832.151801   14037 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769455832.151804   14037 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769455832.151808   14037 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Wrote 652 / 1000 samples to data/rft.json\n",
            "[W126 20:28:13.264936372 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-hUTjPMNMsb",
        "outputId": "ba9a6138-59ae-4ac8-be74-46bf56ab298a"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m homework.rft train --output_dir homework/rft_model --learning_rate 5e-5 --num_train_epochs 5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_RO_sdd8V1p",
        "outputId": "60cf8f8c-815a-4d39-bbab-e5852fa1178c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<frozen runpy>:128: RuntimeWarning: 'homework.rft' found in sys.modules after import of package 'homework', but prior to execution of 'homework.rft'; this may result in unpredictable behaviour\n",
            "2026-01-26 20:29:38.612657: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769459378.633969   28537 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769459378.640036   28537 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769459378.656220   28537 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769459378.656246   28537 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769459378.656250   28537 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769459378.656254   28537 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "trainable params: 8,683,520 || all params: 370,504,640 || trainable%: 2.3437\n",
            "{'loss': 0.6262, 'grad_norm': 0.5107766389846802, 'learning_rate': 4.0099009900990106e-05, 'epoch': 1.19}\n",
            "{'loss': 0.2459, 'grad_norm': 0.42176488041877747, 'learning_rate': 2.7722772277227726e-05, 'epoch': 2.38}\n",
            "{'loss': 0.1898, 'grad_norm': 0.3664196729660034, 'learning_rate': 1.534653465346535e-05, 'epoch': 3.57}\n",
            "{'loss': 0.1688, 'grad_norm': 0.2991567850112915, 'learning_rate': 2.9702970297029703e-06, 'epoch': 4.76}\n",
            "{'train_runtime': 359.0627, 'train_samples_per_second': 9.079, 'train_steps_per_second': 0.292, 'train_loss': 0.3010060219537644, 'epoch': 5.0}\n",
            "100% 105/105 [05:59<00:00,  3.42s/it]\n",
            "LLM Running on Micro Batches 32: 100% 4/4 [00:22<00:00,  5.73s/it]\n",
            "benchmark_result.accuracy=0.59  benchmark_result.answer_rate=1.0\n",
            "[W126 20:36:15.624314237 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m homework.rft test --ckpt_path homework/rft_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nCzpXHFLONk",
        "outputId": "e8b007b7-0b2f-487d-979a-1a53f2793123"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<frozen runpy>:128: RuntimeWarning: 'homework.rft' found in sys.modules after import of package 'homework', but prior to execution of 'homework.rft'; this may result in unpredictable behaviour\n",
            "2026-01-26 20:36:27.100106: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769459787.119634   30284 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769459787.125458   30284 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769459787.140570   30284 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769459787.140597   30284 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769459787.140601   30284 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769459787.140606   30284 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "LLM Running on Micro Batches 32: 100% 4/4 [00:24<00:00,  6.04s/it]\n",
            "benchmark_result.accuracy=0.59  benchmark_result.answer_rate=1.0\n",
            "[W126 20:37:00.313651015 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WODRADDO02Hd"
      },
      "source": [
        "## Grader\n",
        "\n",
        "Run the following cell to grade your homework.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ijkV65Bvpaj",
        "outputId": "394c387f-7dd7-4099-d007-3d518e0c504d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val grader loaded.\n",
            "[DEBUG    00:00:000] Loading assignment\n",
            "[DEBUG    00:02:179] Loading grader\n",
            "[INFO     00:02:179] Model non-batched inference grader\n",
            "2026-01-27 02:31:58.522131: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769481118.555881  121378 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769481118.565974  121378 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769481118.590726  121378 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769481118.590759  121378 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769481118.590767  121378 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769481118.590773  121378 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "100% 32/32 [00:05<00:00,  6.21it/s]\n",
            "[WARNING  00:17:176]   - Test non-batched generate function                 [ 10 / 10  ]\n",
            "WARNING:grader:  - Test non-batched generate function                 [ 10 / 10  ]\n",
            "[INFO     00:17:177]  --------------------------------------------------    [  10 /  10 ]\n",
            "INFO:grader: --------------------------------------------------    [  10 /  10 ]\n",
            "[INFO     00:17:177] Model batched inference grader\n",
            "INFO:grader:Model batched inference grader\n",
            "[WARNING  00:22:006]   - Test batched generate function                     [ 15 / 15  ]\n",
            "WARNING:grader:  - Test batched generate function                     [ 15 / 15  ]\n",
            "[INFO     00:22:006]  --------------------------------------------------    [  15 /  15 ]\n",
            "INFO:grader: --------------------------------------------------    [  15 /  15 ]\n",
            "[INFO     00:22:007] CoT Model Grader\n",
            "INFO:grader:CoT Model Grader\n",
            "[DEBUG    00:40:138] 0.54\n",
            "DEBUG:grader:0.54\n",
            "[WARNING  00:40:149]   - Test the answer accuracy                           [ 25 / 25  ]\n",
            "WARNING:grader:  - Test the answer accuracy                           [ 25 / 25  ]\n",
            "[INFO     00:40:149]  --------------------------------------------------    [  25 /  25 ]\n",
            "INFO:grader: --------------------------------------------------    [  25 /  25 ]\n",
            "[INFO     00:40:149] SFT Model Grader\n",
            "INFO:grader:SFT Model Grader\n",
            "[DEBUG    00:51:620] 0.43\n",
            "DEBUG:grader:0.43\n",
            "[WARNING  00:51:633]   - Test the answer accuracy                           [ 4 / 25  ]\n",
            "WARNING:grader:  - Test the answer accuracy                           [ 4 / 25  ]\n",
            "[INFO     00:51:634]  --------------------------------------------------    [   4 /  25 ]\n",
            "INFO:grader: --------------------------------------------------    [   4 /  25 ]\n",
            "[INFO     00:51:634] RFT Model Grader\n",
            "INFO:grader:RFT Model Grader\n",
            "[DEBUG    01:11:604] 0.58\n",
            "DEBUG:grader:0.58\n",
            "[WARNING  01:11:617]   - Test the answer accuracy                           [ 0 / 25  ]\n",
            "WARNING:grader:  - Test the answer accuracy                           [ 0 / 25  ]\n",
            "[INFO     01:11:618]  --------------------------------------------------    [   0 /  25 ]\n",
            "INFO:grader: --------------------------------------------------    [   0 /  25 ]\n",
            "[INFO     01:11:618] Total                                                     54 / 100\n",
            "INFO:grader:Total                                                     54 / 100\n"
          ]
        }
      ],
      "source": [
        "!python3 -m grader homework -vv --disable_color"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzPcTJQxvYQR",
        "outputId": "777f85d8-69eb-4be3-82bd-fea24c595ff3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bundle.py  \u001b[0m\u001b[01;34mgrader\u001b[0m/    Homework3.ipynb  requirements.txt\n",
            "\u001b[01;34mdata\u001b[0m/      \u001b[01;34mhomework\u001b[0m/  README.md\n",
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "Changes not staged for commit:\n",
            "  (use \"git add/rm <file>...\" to update what will be committed)\n",
            "  (use \"git restore <file>...\" to discard changes in working directory)\n",
            "\t\u001b[31mmodified:   data/rft.json\u001b[m\n",
            "\t\u001b[31mmodified:   homework/rft_model/adapter_config.json\u001b[m\n",
            "\t\u001b[31mmodified:   homework/rft_model/adapter_model.safetensors\u001b[m\n",
            "\t\u001b[31mdeleted:    homework/rft_model/checkpoint-34/README.md\u001b[m\n",
            "\t\u001b[31mdeleted:    homework/rft_model/checkpoint-34/adapter_config.json\u001b[m\n",
            "\t\u001b[31mdeleted:    homework/rft_model/checkpoint-34/adapter_model.safetensors\u001b[m\n",
            "\t\u001b[31mdeleted:    homework/rft_model/checkpoint-34/optimizer.pt\u001b[m\n",
            "\t\u001b[31mdeleted:    homework/rft_model/checkpoint-34/scaler.pt\u001b[m\n",
            "\t\u001b[31mdeleted:    homework/rft_model/checkpoint-34/scheduler.pt\u001b[m\n",
            "\t\u001b[31mdeleted:    homework/rft_model/checkpoint-34/trainer_state.json\u001b[m\n",
            "\t\u001b[31mdeleted:    homework/rft_model/checkpoint-34/training_args.bin\u001b[m\n",
            "\t\u001b[31mdeleted:    homework/rft_model/checkpoint-51/README.md\u001b[m\n",
            "\t\u001b[31mdeleted:    homework/rft_model/checkpoint-51/adapter_config.json\u001b[m\n",
            "\t\u001b[31mdeleted:    homework/rft_model/checkpoint-51/adapter_model.safetensors\u001b[m\n",
            "\t\u001b[31mdeleted:    homework/rft_model/checkpoint-51/optimizer.pt\u001b[m\n",
            "\t\u001b[31mdeleted:    homework/rft_model/checkpoint-51/scaler.pt\u001b[m\n",
            "\t\u001b[31mdeleted:    homework/rft_model/checkpoint-51/scheduler.pt\u001b[m\n",
            "\t\u001b[31mdeleted:    homework/rft_model/checkpoint-51/trainer_state.json\u001b[m\n",
            "\t\u001b[31mdeleted:    homework/rft_model/checkpoint-51/training_args.bin\u001b[m\n",
            "\t\u001b[31mmodified:   homework/sft_model/adapter_config.json\u001b[m\n",
            "\t\u001b[31mmodified:   homework/sft_model/adapter_model.safetensors\u001b[m\n",
            "\t\u001b[31mmodified:   homework/sft_model/checkpoint-128/adapter_config.json\u001b[m\n",
            "\t\u001b[31mmodified:   homework/sft_model/checkpoint-128/adapter_model.safetensors\u001b[m\n",
            "\t\u001b[31mmodified:   homework/sft_model/checkpoint-128/optimizer.pt\u001b[m\n",
            "\t\u001b[31mdeleted:    homework/sft_model/checkpoint-128/scaler.pt\u001b[m\n",
            "\t\u001b[31mmodified:   homework/sft_model/checkpoint-128/scheduler.pt\u001b[m\n",
            "\t\u001b[31mmodified:   homework/sft_model/checkpoint-128/trainer_state.json\u001b[m\n",
            "\t\u001b[31mmodified:   homework/sft_model/checkpoint-128/training_args.bin\u001b[m\n",
            "\t\u001b[31mmodified:   homework/sft_model/checkpoint-160/adapter_config.json\u001b[m\n",
            "\t\u001b[31mmodified:   homework/sft_model/checkpoint-160/adapter_model.safetensors\u001b[m\n",
            "\t\u001b[31mmodified:   homework/sft_model/checkpoint-160/optimizer.pt\u001b[m\n",
            "\t\u001b[31mdeleted:    homework/sft_model/checkpoint-160/scaler.pt\u001b[m\n",
            "\t\u001b[31mmodified:   homework/sft_model/checkpoint-160/scheduler.pt\u001b[m\n",
            "\t\u001b[31mmodified:   homework/sft_model/checkpoint-160/trainer_state.json\u001b[m\n",
            "\t\u001b[31mmodified:   homework/sft_model/checkpoint-160/training_args.bin\u001b[m\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\t\u001b[31mhomework/rft_model/checkpoint-105/\u001b[m\n",
            "\t\u001b[31mhomework/rft_model/checkpoint-84/\u001b[m\n",
            "\n",
            "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
          ]
        }
      ],
      "source": [
        "%ls\n",
        "!git status"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "id": "pVOEEkb_bz-P",
        "outputId": "aad3aa32-fed6-462f-a4c2-0063c025683c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiUnZ58P0iZF",
        "outputId": "e36a33a4-9ef6-44e4-d731-44a547bd468a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[main e6e3249] colab update\n",
            " 38 files changed, 3409 insertions(+), 2691 deletions(-)\n",
            " rewrite homework3/data/rft.json (62%)\n",
            " rename homework3/homework/rft_model/{checkpoint-34 => checkpoint-105}/README.md (100%)\n",
            " rename homework3/homework/rft_model/{checkpoint-51 => checkpoint-105}/adapter_config.json (97%)\n",
            " create mode 100644 homework3/homework/rft_model/checkpoint-105/adapter_model.safetensors\n",
            " create mode 100644 homework3/homework/rft_model/checkpoint-105/optimizer.pt\n",
            " rename homework3/homework/rft_model/{checkpoint-51 => checkpoint-105}/scheduler.pt (71%)\n",
            " create mode 100644 homework3/homework/rft_model/checkpoint-105/trainer_state.json\n",
            " create mode 100644 homework3/homework/rft_model/checkpoint-105/training_args.bin\n",
            " delete mode 100644 homework3/homework/rft_model/checkpoint-34/scaler.pt\n",
            " delete mode 100644 homework3/homework/rft_model/checkpoint-34/training_args.bin\n",
            " delete mode 100644 homework3/homework/rft_model/checkpoint-51/scaler.pt\n",
            " delete mode 100644 homework3/homework/rft_model/checkpoint-51/trainer_state.json\n",
            " delete mode 100644 homework3/homework/rft_model/checkpoint-51/training_args.bin\n",
            " rename homework3/homework/rft_model/{checkpoint-51 => checkpoint-84}/README.md (100%)\n",
            " rename homework3/homework/rft_model/{checkpoint-34 => checkpoint-84}/adapter_config.json (97%)\n",
            " rename homework3/homework/rft_model/{checkpoint-51 => checkpoint-84}/adapter_model.safetensors (75%)\n",
            " rename homework3/homework/rft_model/{checkpoint-34 => checkpoint-84}/optimizer.pt (82%)\n",
            " rename homework3/homework/rft_model/{checkpoint-34 => checkpoint-84}/scheduler.pt (66%)\n",
            " rename homework3/homework/rft_model/{checkpoint-34 => checkpoint-84}/trainer_state.json (53%)\n",
            " create mode 100644 homework3/homework/rft_model/checkpoint-84/training_args.bin\n",
            " rename homework3/homework/{rft_model/checkpoint-34 => sft_model/checkpoint-128}/adapter_model.safetensors (75%)\n",
            " rename homework3/homework/{rft_model/checkpoint-51 => sft_model/checkpoint-128}/optimizer.pt (82%)\n",
            " delete mode 100644 homework3/homework/sft_model/checkpoint-128/scaler.pt\n",
            " delete mode 100644 homework3/homework/sft_model/checkpoint-160/scaler.pt\n",
            "Enumerating objects: 47, done.\n",
            "Counting objects: 100% (47/47), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (32/32), done.\n",
            "Writing objects: 100% (32/32), 367.00 MiB | 12.13 MiB/s, done.\n",
            "Total 32 (delta 14), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (14/14), completed with 6 local objects.\u001b[K\n",
            "remote: \u001b[1;33mwarning\u001b[m: See https://gh.io/lfs for more information.\u001b[K\n",
            "remote: \u001b[1;33mwarning\u001b[m: File homework3/homework/rft_model/checkpoint-105/optimizer.pt is 66.61 MB; this is larger than GitHub's recommended maximum file size of 50.00 MB\u001b[K\n",
            "remote: \u001b[1;33mwarning\u001b[m: File homework3/homework/rft_model/checkpoint-84/optimizer.pt is 66.61 MB; this is larger than GitHub's recommended maximum file size of 50.00 MB\u001b[K\n",
            "remote: \u001b[1;33mwarning\u001b[m: File homework3/homework/sft_model/checkpoint-128/optimizer.pt is 66.61 MB; this is larger than GitHub's recommended maximum file size of 50.00 MB\u001b[K\n",
            "remote: \u001b[1;33mwarning\u001b[m: File homework3/homework/sft_model/checkpoint-160/optimizer.pt is 66.61 MB; this is larger than GitHub's recommended maximum file size of 50.00 MB\u001b[K\n",
            "remote: \u001b[1;33mwarning\u001b[m: GH001: Large files detected. You may want to try Git Large File Storage - https://git-lfs.github.com.\u001b[K\n",
            "To https://github.com/chaalp/advances_in_deep_learning.git\n",
            "   916366d..e6e3249  main -> main\n"
          ]
        }
      ],
      "source": [
        "# Be careful not to \"git add *\" since there are datasets and logs\n",
        "!git add .\n",
        "!git config --global user.email \"chander_alphonse@yahoo.com\"\n",
        "!git config --global user.name \"chaalp\"\n",
        "!git commit -m \"colab update\"\n",
        "!git push"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiCe-RX-J6CF"
      },
      "source": [
        "## Update your changes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxbPtnF55AMU"
      },
      "source": [
        "## Submission\n",
        "\n",
        "Run the following cell to bundle your submission (modify UTID accordingly).\n",
        "\n",
        "If you notice that your bundle is too large, you can modify the `bundle.py` script and ignore large files by adding them manually to `BLACKLIST`.\n",
        "\n",
        "After the bundler and grader run, right click and download your bundled `.zip` file from the Colab UI.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M07WA1Os4Xxh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "433560bb-eeac-4b1c-9a2f-27c9f62a3ae9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokenize.py\n",
            "data.py\n",
            "__init__.py\n",
            "ae.py\n",
            "bsq.py\n",
            "train.py\n",
            "generation.py\n",
            "compress.py\n",
            "PatchAutoEncoder.pth\n",
            "AutoregressiveModel.pth\n",
            "BSQPatchAutoEncoder.pth\n",
            "autoregressive.py\n",
            "Submission created: /content/advances_in_deep_learning/homework2/ca37464.zip 7.85 MB\n",
            "Val grader loaded.\n",
            "[DEBUG    00:00:000] Loading assignment\n",
            "[DEBUG    00:00:088] Loading grader\n",
            "[INFO     00:00:089] Patch AutoEncoder\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[DEBUG    00:00:100] Loading PatchAutoEncoder from /tmp/tmpe52uuqhj/homework/PatchAutoEncoder.pth\n",
            "[DEBUG    00:02:018] Validation loss: 0.005878145806491375\n",
            "[WARNING  00:02:019]   - Image Reconstruction MSE Loss                      [ 30 / 30  ]\n",
            "[INFO     00:02:020]  --------------------------------------------------    [  30 /  30 ]\n",
            "[INFO     00:02:020] BSQ Patch AutoEncoder\n",
            "[DEBUG    00:02:031] Loading BSQPatchAutoEncoder from /tmp/tmpe52uuqhj/homework/BSQPatchAutoEncoder.pth\n",
            "[DEBUG    00:03:758] Validation loss: 0.004041745327413082\n",
            "[WARNING  00:03:760]   - Image Reconstruction MSE Loss                      [ 30 / 30  ]\n",
            "[INFO     00:03:760]  --------------------------------------------------    [  30 /  30 ]\n",
            "[INFO     00:03:761] Autoregressive Model\n",
            "[DEBUG    00:03:772] Loading AutoregressiveModel from /tmp/tmpe52uuqhj/homework/AutoregressiveModel.pth\n",
            "[DEBUG    00:03:786] Loading BSQPatchAutoEncoder from /tmp/tmpe52uuqhj/homework/BSQPatchAutoEncoder.pth\n",
            "Compute validation autoregressive loss:   0% 0/40 [00:00<?, ?it/s][DEBUG    00:04:325] loss: 2765.43408203125\n",
            "Compute validation autoregressive loss:   2% 1/40 [00:00<00:20,  1.87it/s][DEBUG    00:04:420] loss: 2626.9951171875\n",
            "[DEBUG    00:04:509] loss: 2689.6494140625\n",
            "Compute validation autoregressive loss:   8% 3/40 [00:00<00:07,  4.85it/s][DEBUG    00:04:599] loss: 2740.5009765625\n",
            "[DEBUG    00:04:687] loss: 2799.07177734375\n",
            "Compute validation autoregressive loss:  12% 5/40 [00:00<00:05,  6.85it/s][DEBUG    00:04:777] loss: 2667.234619140625\n",
            "[DEBUG    00:04:866] loss: 2748.378173828125\n",
            "Compute validation autoregressive loss:  18% 7/40 [00:01<00:04,  8.19it/s][DEBUG    00:04:955] loss: 2894.95068359375\n",
            "[DEBUG    00:05:044] loss: 2782.253662109375\n",
            "Compute validation autoregressive loss:  22% 9/40 [00:01<00:03,  9.12it/s][DEBUG    00:05:133] loss: 2713.906494140625\n",
            "[DEBUG    00:05:227] loss: 2679.927734375\n",
            "Compute validation autoregressive loss:  28% 11/40 [00:01<00:02,  9.68it/s][DEBUG    00:05:315] loss: 2610.4541015625\n",
            "[DEBUG    00:05:405] loss: 2699.767333984375\n",
            "Compute validation autoregressive loss:  32% 13/40 [00:01<00:02, 10.15it/s][DEBUG    00:05:498] loss: 2830.227294921875\n",
            "[DEBUG    00:05:589] loss: 2834.3486328125\n",
            "Compute validation autoregressive loss:  38% 15/40 [00:01<00:02, 10.37it/s][DEBUG    00:05:677] loss: 2797.982421875\n",
            "[DEBUG    00:05:776] loss: 2805.5234375\n",
            "Compute validation autoregressive loss:  42% 17/40 [00:01<00:02, 10.47it/s][DEBUG    00:05:869] loss: 2703.28759765625\n",
            "[DEBUG    00:05:958] loss: 2708.708740234375\n",
            "Compute validation autoregressive loss:  48% 19/40 [00:02<00:01, 10.61it/s][DEBUG    00:06:047] loss: 2717.50732421875\n",
            "[DEBUG    00:06:137] loss: 2834.374755859375\n",
            "Compute validation autoregressive loss:  52% 21/40 [00:02<00:01, 10.78it/s][DEBUG    00:06:225] loss: 2659.37841796875\n",
            "[DEBUG    00:06:323] loss: 2736.813720703125\n",
            "Compute validation autoregressive loss:  57% 23/40 [00:02<00:01, 10.78it/s][DEBUG    00:06:417] loss: 2871.53076171875\n",
            "[DEBUG    00:06:508] loss: 2800.853515625\n",
            "Compute validation autoregressive loss:  62% 25/40 [00:02<00:01, 10.79it/s][DEBUG    00:06:602] loss: 2750.362060546875\n",
            "[DEBUG    00:06:693] loss: 2834.1533203125\n",
            "Compute validation autoregressive loss:  68% 27/40 [00:02<00:01, 10.79it/s][DEBUG    00:06:786] loss: 2839.320068359375\n",
            "[DEBUG    00:06:872] loss: 2729.368896484375\n",
            "Compute validation autoregressive loss:  72% 29/40 [00:03<00:01, 10.90it/s][DEBUG    00:06:961] loss: 2806.20703125\n",
            "[DEBUG    00:07:051] loss: 2737.31689453125\n",
            "Compute validation autoregressive loss:  78% 31/40 [00:03<00:00, 10.99it/s][DEBUG    00:07:143] loss: 2745.277099609375\n",
            "[DEBUG    00:07:232] loss: 2720.09619140625\n",
            "Compute validation autoregressive loss:  82% 33/40 [00:03<00:00, 11.01it/s][DEBUG    00:07:320] loss: 2816.864013671875\n",
            "[DEBUG    00:07:409] loss: 2773.227783203125\n",
            "Compute validation autoregressive loss:  88% 35/40 [00:03<00:00, 11.08it/s][DEBUG    00:07:498] loss: 2646.795654296875\n",
            "[DEBUG    00:07:587] loss: 2749.90966796875\n",
            "Compute validation autoregressive loss:  92% 37/40 [00:03<00:00, 11.14it/s][DEBUG    00:07:677] loss: 2701.375244140625\n",
            "[DEBUG    00:07:764] loss: 2643.17529296875\n",
            "Compute validation autoregressive loss:  98% 39/40 [00:03<00:00, 11.18it/s][DEBUG    00:07:852] loss: 2629.1298828125\n",
            "Compute validation autoregressive loss: 100% 40/40 [00:04<00:00,  9.75it/s]\n",
            "[DEBUG    00:07:895] Validation loss: 2746.0409973144533\n",
            "[WARNING  00:07:896]   - Autoregressive prediction loss                     [ 15 / 15  ]\n",
            "[DEBUG    00:07:897] Loading AutoregressiveModel from /tmp/tmpe52uuqhj/homework/AutoregressiveModel.pth\n",
            "[DEBUG    00:07:910] Loading BSQPatchAutoEncoder from /tmp/tmpe52uuqhj/homework/BSQPatchAutoEncoder.pth\n",
            "[DEBUG    00:08:164] token change ratio: 0.43\n",
            "[WARNING  00:08:166]   - Check autoregressiveness of the model              [ 15 / 15  ]\n",
            "[INFO     00:08:166]  --------------------------------------------------    [  30 /  30 ]\n",
            "[INFO     00:08:166] Image Generation from Autoregressive Model\n",
            "[DEBUG    00:08:167] Loading AutoregressiveModel from /tmp/tmpe52uuqhj/homework/AutoregressiveModel.pth\n",
            "[DEBUG    00:08:180] Loading BSQPatchAutoEncoder from /tmp/tmpe52uuqhj/homework/BSQPatchAutoEncoder.pth\n",
            "[DEBUG    00:08:185] generating 8 images from the autoregressive model\n",
            "[DEBUG    00:14:563] Generation NLL: 2.999892473220825\n",
            "[WARNING  00:14:574]   - Check image generation from the model              [ 10 / 10  ]\n",
            "[INFO     00:14:574]  --------------------------------------------------    [  10 /  10 ]\n",
            "[INFO     00:14:574] Image Compression\n",
            "[DEBUG    00:14:577] Loading AutoregressiveModel from /tmp/tmpe52uuqhj/homework/AutoregressiveModel.pth\n",
            "[DEBUG    00:14:589] Loading BSQPatchAutoEncoder from /tmp/tmpe52uuqhj/homework/BSQPatchAutoEncoder.pth\n",
            "Checking compression:   0% 0/5 [00:00<?, ?it/s]\n",
            "[WARNING  00:14:603]   - Check image compression ratio and reconstruction quality [ 0 / 5 Not Implemented ]\n",
            "[INFO     00:14:603]  --------------------------------------------------    [   0 /   5 ]\n",
            "[INFO     00:14:603] Total                                                    100 / 105\n"
          ]
        }
      ],
      "source": [
        "!python3 bundle.py homework ca37464\n",
        "\n",
        "# optional: run the grader with your bundled homework to double check\n",
        "!python3 -m grader ca37464.zip -vv --disable_color"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
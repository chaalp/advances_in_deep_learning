{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gxzo13BN6FL0"
      },
      "source": [
        "## Code Setup\n",
        "\n",
        "Move into `homework3/`.\n",
        "\n",
        "This will be the main working directory and the training/grading must be run from this directory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "et3KFSXs3IHk",
        "outputId": "df15d960-e345-44a0-9b8a-7e333e79850c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/advances_in_deep_learning\n",
            "\u001b[0m\u001b[01;34mhomework1\u001b[0m/  \u001b[01;34mhomework2\u001b[0m/  \u001b[01;34mhomework3\u001b[0m/  \u001b[01;34mhomework4\u001b[0m/\n",
            "/content/advances_in_deep_learning/homework3\n",
            "bundle.py  \u001b[0m\u001b[01;34mgrader\u001b[0m/    Homework3.ipynb  requirements.txt\n",
            "\u001b[01;34mdata\u001b[0m/      \u001b[01;34mhomework\u001b[0m/  README.md\n"
          ]
        }
      ],
      "source": [
        "# navigate to your repo\n",
        "%cd /content/advances_in_deep_learning\n",
        "%ls\n",
        "\n",
        "# go to a specific homework\n",
        "%cd homework3\n",
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLy_5AIgF62F",
        "outputId": "cf7c6767-f59e-444e-a923-ddf1a1b0a21e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Q4sbuDqn3tq",
        "outputId": "49811a45-d6fa-45af-a7c6-f69bc94d3aca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fire>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from -r ./requirements.txt (line 1)) (0.7.1)\n",
            "Requirement already satisfied: lightning>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from -r ./requirements.txt (line 2)) (2.6.0)\n",
            "Requirement already satisfied: torch>=2.6.0 in /usr/local/lib/python3.12/dist-packages (from -r ./requirements.txt (line 3)) (2.9.0+cpu)\n",
            "Requirement already satisfied: transformers==4.52.4 in /usr/local/lib/python3.12/dist-packages (from -r ./requirements.txt (line 4)) (4.52.4)\n",
            "Requirement already satisfied: numpy>=2.2.1 in /usr/local/lib/python3.12/dist-packages (from -r ./requirements.txt (line 5)) (2.4.1)\n",
            "Requirement already satisfied: Pillow>=11.1.0 in /usr/local/lib/python3.12/dist-packages (from -r ./requirements.txt (line 6)) (11.3.0)\n",
            "Requirement already satisfied: tqdm>=4.66.0 in /usr/local/lib/python3.12/dist-packages (from -r ./requirements.txt (line 7)) (4.67.1)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.12/dist-packages (from -r ./requirements.txt (line 8)) (1.12.0)\n",
            "Requirement already satisfied: tensorboard>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from -r ./requirements.txt (line 9)) (2.19.0)\n",
            "Requirement already satisfied: peft>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from -r ./requirements.txt (line 10)) (0.18.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.52.4->-r ./requirements.txt (line 4)) (3.20.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.52.4->-r ./requirements.txt (line 4)) (0.36.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.52.4->-r ./requirements.txt (line 4)) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.52.4->-r ./requirements.txt (line 4)) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.52.4->-r ./requirements.txt (line 4)) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.52.4->-r ./requirements.txt (line 4)) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers==4.52.4->-r ./requirements.txt (line 4)) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers==4.52.4->-r ./requirements.txt (line 4)) (0.7.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from fire>=0.7.0->-r ./requirements.txt (line 1)) (3.3.0)\n",
            "Requirement already satisfied: fsspec<2027.0,>=2022.5.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning>=2.5.0->-r ./requirements.txt (line 2)) (2025.3.0)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from lightning>=2.5.0->-r ./requirements.txt (line 2)) (0.15.2)\n",
            "Requirement already satisfied: torchmetrics<3.0,>0.7.0 in /usr/local/lib/python3.12/dist-packages (from lightning>=2.5.0->-r ./requirements.txt (line 2)) (1.8.2)\n",
            "Requirement already satisfied: typing-extensions<6.0,>4.5.0 in /usr/local/lib/python3.12/dist-packages (from lightning>=2.5.0->-r ./requirements.txt (line 2)) (4.15.0)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.12/dist-packages (from lightning>=2.5.0->-r ./requirements.txt (line 2)) (2.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.6.0->-r ./requirements.txt (line 3)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6.0->-r ./requirements.txt (line 3)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6.0->-r ./requirements.txt (line 3)) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6.0->-r ./requirements.txt (line 3)) (3.1.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.26.0->-r ./requirements.txt (line 8)) (5.9.5)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.15.0->-r ./requirements.txt (line 9)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.15.0->-r ./requirements.txt (line 9)) (1.76.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.15.0->-r ./requirements.txt (line 9)) (3.10)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.15.0->-r ./requirements.txt (line 9)) (5.29.5)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.15.0->-r ./requirements.txt (line 9)) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.15.0->-r ./requirements.txt (line 9)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.15.0->-r ./requirements.txt (line 9)) (3.1.5)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning>=2.5.0->-r ./requirements.txt (line 2)) (3.13.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.4->-r ./requirements.txt (line 4)) (1.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.6.0->-r ./requirements.txt (line 3)) (1.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.15.0->-r ./requirements.txt (line 9)) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.52.4->-r ./requirements.txt (line 4)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.52.4->-r ./requirements.txt (line 4)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.52.4->-r ./requirements.txt (line 4)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.52.4->-r ./requirements.txt (line 4)) (2026.1.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.5.0->-r ./requirements.txt (line 2)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.5.0->-r ./requirements.txt (line 2)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.5.0->-r ./requirements.txt (line 2)) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.5.0->-r ./requirements.txt (line 2)) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.5.0->-r ./requirements.txt (line 2)) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.5.0->-r ./requirements.txt (line 2)) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.5.0->-r ./requirements.txt (line 2)) (1.22.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r ./requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m homework.base_llm test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHp2gIug-Xgz",
        "outputId": "8c445ebd-9d16-4e6e-e9ab-a891b1a2fc7a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<frozen runpy>:128: RuntimeWarning: 'homework.base_llm' found in sys.modules after import of package 'homework', but prior to execution of 'homework.base_llm'; this may result in unpredictable behaviour\n",
            "tokenizer_config.json: 3.76kB [00:00, 8.75MB/s]\n",
            "vocab.json: 801kB [00:00, 17.3MB/s]\n",
            "merges.txt: 466kB [00:00, 22.2MB/s]\n",
            "tokenizer.json: 2.10MB [00:00, 33.9MB/s]\n",
            "special_tokens_map.json: 100% 655/655 [00:00<00:00, 2.26MB/s]\n",
            "config.json: 100% 846/846 [00:00<00:00, 5.42MB/s]\n",
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n",
            "2026-01-26 17:07:48.234876: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2026-01-26 17:07:48.242375: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2026-01-26 17:07:48.262444: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769447268.297060    1238 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769447268.309606    1238 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769447268.342695    1238 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769447268.342766    1238 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769447268.342775    1238 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769447268.342782    1238 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-26 17:07:48.351569: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "model.safetensors: 100% 724M/724M [00:09<00:00, 74.2MB/s]\n",
            "generation_config.json: 100% 132/132 [00:00<00:00, 766kB/s]\n",
            "testing generate function\n",
            "input The cat went up\n",
            "output  the stairs, and the cat went up the stairs, and the cat went up the stairs, and the cat went up the stairs, and the cat went up the stairs, and the cat went up the stairs, and the cat went up the stairs\n",
            "testing generate function\n",
            "input The dog went down\n",
            "output  the stairs and into the basement.\n",
            "\n",
            "The dog went down the stairs and into the basement.\n",
            "\n",
            "Which sentence is correct?\n",
            "[' the stairs, and the cat went up the stairs, and the cat went up the stairs, and the cat went up the stairs, and the cat went up the stairs, and the cat went up the stairs, and the cat went up the stairs', ' the stairs and into the basement.\\n\\nThe dog went down the stairs and into the basement.\\n\\nWhich sentence is correct?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLe2Ti0xJeIL",
        "outputId": "d86053cf-72dc-4b08-d998-56e5276bdc2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects:  11% (1/9)\u001b[K\rremote: Counting objects:  22% (2/9)\u001b[K\rremote: Counting objects:  33% (3/9)\u001b[K\rremote: Counting objects:  44% (4/9)\u001b[K\rremote: Counting objects:  55% (5/9)\u001b[K\rremote: Counting objects:  66% (6/9)\u001b[K\rremote: Counting objects:  77% (7/9)\u001b[K\rremote: Counting objects:  88% (8/9)\u001b[K\rremote: Counting objects: 100% (9/9)\u001b[K\rremote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1)\u001b[K\rremote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 5 (delta 4), reused 5 (delta 4), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects:  20% (1/5)\rUnpacking objects:  40% (2/5)\rUnpacking objects:  60% (3/5)\rUnpacking objects:  80% (4/5)\rUnpacking objects: 100% (5/5)\rUnpacking objects: 100% (5/5), 785 bytes | 392.00 KiB/s, done.\n",
            "From https://github.com/chaalp/advances_in_deep_learning\n",
            "   1bbeaa1..8aabe69  main       -> origin/main\n",
            "Updating 1bbeaa1..8aabe69\n",
            "Fast-forward\n",
            " homework3/homework/cot.py | 24 \u001b[32m+++++++++++++\u001b[m\u001b[31m-----------\u001b[m\n",
            " 1 file changed, 13 insertions(+), 11 deletions(-)\n"
          ]
        }
      ],
      "source": [
        "!git pull"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m homework.cot test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvfc-tviCAiT",
        "outputId": "4024afc1-2c4a-440b-c819-03ab7492912c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<frozen runpy>:128: RuntimeWarning: 'homework.cot' found in sys.modules after import of package 'homework', but prior to execution of 'homework.cot'; this may result in unpredictable behaviour\n",
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n",
            "2026-01-26 17:39:09.594567: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2026-01-26 17:39:09.601922: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2026-01-26 17:39:09.623198: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769449149.668273    8917 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769449149.680630    8917 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769449149.708083    8917 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769449149.708145    8917 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769449149.708154    8917 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769449149.708162    8917 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-26 17:39:09.716759: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "LLM Running on Micro Batches 32: 100% 4/4 [07:26<00:00, 111.68s/it]\n",
            "benchmark_result.accuracy=0.52  benchmark_result.answer_rate=0.89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "id": "SahCpmkgxlft",
        "outputId": "5af6009c-dd18-489e-8f8a-c583fb63f1b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from homework.sft import format_example\n",
        "print(format_example(\"How many grams in 6 kg?\", 6000.0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZZqiQbaG8_6",
        "outputId": "39e53cc8-40f0-40bc-d7bc-ae14a57d3cdb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'question': 'How many grams in 6 kg? Answer with <answer>...</answer>.', 'answer': '<answer>6000</answer>'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMdH1QLi7kgW",
        "outputId": "15cb3eb7-3fb3-454f-fbdd-4349dc17de72"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 13, done.\u001b[K\n",
            "remote: Counting objects:   7% (1/13)\u001b[K\rremote: Counting objects:  15% (2/13)\u001b[K\rremote: Counting objects:  23% (3/13)\u001b[K\rremote: Counting objects:  30% (4/13)\u001b[K\rremote: Counting objects:  38% (5/13)\u001b[K\rremote: Counting objects:  46% (6/13)\u001b[K\rremote: Counting objects:  53% (7/13)\u001b[K\rremote: Counting objects:  61% (8/13)\u001b[K\rremote: Counting objects:  69% (9/13)\u001b[K\rremote: Counting objects:  76% (10/13)\u001b[K\rremote: Counting objects:  84% (11/13)\u001b[K\rremote: Counting objects:  92% (12/13)\u001b[K\rremote: Counting objects: 100% (13/13)\u001b[K\rremote: Counting objects: 100% (13/13), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1)\u001b[K\rremote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 7 (delta 6), reused 7 (delta 6), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects:  14% (1/7)\rUnpacking objects:  28% (2/7)\rUnpacking objects:  42% (3/7)\rUnpacking objects:  57% (4/7)\rUnpacking objects:  71% (5/7)\rUnpacking objects:  85% (6/7)\rUnpacking objects: 100% (7/7)\rUnpacking objects: 100% (7/7), 851 bytes | 212.00 KiB/s, done.\n",
            "From https://github.com/chaalp/advances_in_deep_learning\n",
            "   cf6d13f..4d2907e  main       -> origin/main\n",
            "Updating cf6d13f..4d2907e\n",
            "Fast-forward\n",
            " homework3/homework/base_llm.py |  4 \u001b[32m+++\u001b[m\u001b[31m-\u001b[m\n",
            " homework3/homework/rft.py      | 15 \u001b[32m++++++++\u001b[m\u001b[31m-------\u001b[m\n",
            " homework3/homework/sft.py      | 13 \u001b[32m+++++++\u001b[m\u001b[31m------\u001b[m\n",
            " 3 files changed, 18 insertions(+), 14 deletions(-)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m homework.sft train --output_dir homework/sft_model --learning_rate 5e-5 --num_train_epochs 5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ilcx-LSt7tye",
        "outputId": "c01bbd0d-cd1d-4b98-c3c2-3d5b12343e33"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<frozen runpy>:128: RuntimeWarning: 'homework.sft' found in sys.modules after import of package 'homework', but prior to execution of 'homework.sft'; this may result in unpredictable behaviour\n",
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n",
            "2026-01-26 18:10:26.628439: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2026-01-26 18:10:26.634589: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2026-01-26 18:10:26.666674: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769451026.716864   16466 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769451026.735320   16466 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769451026.776088   16466 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769451026.776164   16466 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769451026.776169   16466 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769451026.776174   16466 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-26 18:10:26.787422: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "trainable params: 8,683,520 || all params: 370,504,640 || trainable%: 2.3437\n",
            "  0% 0/160 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "  4% 7/160 [23:29<8:20:05, 196.11s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from homework.base_llm import BaseLLM\n",
        "from peft import PeftModel\n",
        "\n",
        "llm = BaseLLM()\n",
        "llm.model = PeftModel.from_pretrained(llm.model, \"homework/sft_model\").to(llm.device)\n",
        "llm.model.eval()\n",
        "\n",
        "qs = [\n",
        "  \"How many grams are there in 6 kg?\",\n",
        "  \"How many feet are in 3 yards?\",\n",
        "  \"How many minutes are in 2 hours?\",\n",
        "]\n",
        "prompts = [llm.format_prompt(q) for q in qs]\n",
        "gens = llm.batched_generate(prompts)\n",
        "\n",
        "for q,g in zip(qs, gens):\n",
        "  print(\"\\nQ:\", q)\n",
        "  print(\"GEN:\", g)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3N6woXVvzuZ",
        "outputId": "469f018b-5254-403c-f3f6-8331496de4ee"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Q: How many grams are there in 6 kg?\n",
            "GEN: \n",
            "\n",
            "\n",
            "Q: How many feet are in 3 yards?\n",
            "GEN: \n",
            "\n",
            "\n",
            "Q: How many minutes are in 2 hours?\n",
            "GEN: \n",
            "A:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import homework.base_llm as m\n",
        "import inspect\n",
        "\n",
        "print(\"IMPORTED FROM:\", m.__file__)\n",
        "print(\"\\n--- batched_generate source ---\")\n",
        "print(inspect.getsource(m.BaseLLM.batched_generate))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwqDfqSX8Cjf",
        "outputId": "962a5bf1-b28e-4180-9dbb-8385a907b549"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IMPORTED FROM: /content/advances_in_deep_learning/homework3/homework/base_llm.py\n",
            "\n",
            "--- batched_generate source ---\n",
            "    def batched_generate(\n",
            "        self, prompts: list[str], num_return_sequences: int | None = None, temperature: float = 0\n",
            "    ) -> list[str] | list[list[str]]:\n",
            "        \"\"\"\n",
            "        Batched version of `generate` method.\n",
            "\n",
            "        You will likely get an up to 10x speedup using batched decoding.\n",
            "\n",
            "        To implement batch decoding you will need to:\n",
            "        - tokenize the prompts self.tokenizer with padding=True and return_tensors=\"pt\"\n",
            "        - call self.model.generate\n",
            "        - decode the outputs with self.tokenizer.batch_decode\n",
            "\n",
            "        Tip: You need to set self.tokenizer.padding_side = \"left\" to get the correct padding behavior for generation.\n",
            "             Left padding makes sure all sequences are aligned to the right (i.e. where tokens are generated).\n",
            "        Tip: self.model.generate takes a lot of parameters. Here are some relevant ones:\n",
            "            - max_new_tokens: The maximum number of tokens to generate. Set this to a reasonable value\n",
            "                              (50 should suffice).\n",
            "            - do_sample and temperature: For any temperature > 0, set do_sample=True.\n",
            "                                         do_sample=False will use greedy decoding.\n",
            "            - num_return_sequences: The number of sequences to return. Note that this will generate a flat\n",
            "                                    list of len(prompts) * num_return_sequences entries.\n",
            "            - eos_token_id: The end of sequence token id. This is used to stop generation. Set this\n",
            "                            to self.tokenizer.eos_token_id.\n",
            "        Pro Tip: Only batch_decode generated tokens by masking out the inputs with\n",
            "                 outputs[:, len(inputs[\"input_ids\"][0]) :]\n",
            "        \"\"\"\n",
            "        from tqdm import tqdm  # Importing tqdm for progress bar\n",
            "\n",
            "        # Preventing OOM\n",
            "        # Depending on your GPU batched generation will use a lot of memory.\n",
            "        # If you run out of memory, try to reduce the micro_batch_size.\n",
            "        micro_batch_size = 32\n",
            "        if len(prompts) > micro_batch_size:\n",
            "            return [\n",
            "                r\n",
            "                for idx in tqdm(\n",
            "                    range(0, len(prompts), micro_batch_size), desc=f\"LLM Running on Micro Batches {micro_batch_size}\"\n",
            "                )\n",
            "                for r in self.batched_generate(prompts[idx : idx + micro_batch_size], num_return_sequences, temperature)\n",
            "            ]\n",
            "\n",
            "        #raise NotImplementedError()\n",
            "\n",
            "        self.tokenizer.padding_side = \"left\"\n",
            "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
            "\n",
            "        # Tokenize\n",
            "        inputs = self.tokenizer(\n",
            "            prompts,\n",
            "            padding=True,\n",
            "            truncation=True,\n",
            "            return_tensors=\"pt\",\n",
            "        )\n",
            "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
            "\n",
            "        # Generation params\n",
            "        gen_kwargs = dict(\n",
            "            max_new_tokens=50,\n",
            "            min_new_tokens=1,\n",
            "            eos_token_id=self.tokenizer.eos_token_id,\n",
            "            pad_token_id=self.tokenizer.eos_token_id,\n",
            "        )\n",
            "\n",
            "        if temperature and temperature > 0:\n",
            "            gen_kwargs.update(\n",
            "                do_sample=True,\n",
            "                temperature=float(temperature),\n",
            "            )\n",
            "        else:\n",
            "            gen_kwargs.update(\n",
            "                do_sample=False,\n",
            "            )\n",
            "\n",
            "        if num_return_sequences is not None:\n",
            "            gen_kwargs[\"num_return_sequences\"] = int(num_return_sequences)\n",
            "\n",
            "        # Generate\n",
            "        with torch.no_grad():\n",
            "            outputs = self.model.generate(\n",
            "                input_ids=inputs[\"input_ids\"],\n",
            "                attention_mask=inputs[\"attention_mask\"],\n",
            "                **gen_kwargs,\n",
            "            )\n",
            "\n",
            "        # Decode ONLY the newly generated tokens (mask out prompt)\n",
            "        prompt_len = inputs[\"input_ids\"].shape[1]\n",
            "        gen_tokens = outputs[:, prompt_len:]\n",
            "\n",
            "        decoded = self.tokenizer.batch_decode(gen_tokens, skip_special_tokens=True)\n",
            "\n",
            "        # If we generated multiple sequences per prompt, reshape to list[list[str]]\n",
            "        if num_return_sequences is not None:\n",
            "            n = len(prompts)\n",
            "            k = int(num_return_sequences)\n",
            "            return [decoded[i * k : (i + 1) * k] for i in range(n)]\n",
            "\n",
            "        return decoded\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from homework.base_llm import BaseLLM\n",
        "from peft import PeftModel\n",
        "\n",
        "llm = BaseLLM()\n",
        "llm.model = PeftModel.from_pretrained(llm.model, \"homework/sft_model\").to(llm.device)\n",
        "llm.model.eval()\n",
        "\n",
        "prompt = \"How many grams are there in 6 kg? Answer with <answer>...</answer>.\"\n",
        "inputs = llm.tokenizer([prompt], padding=True, return_tensors=\"pt\").to(llm.device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    out = llm.model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=10,\n",
        "        do_sample=False,\n",
        "        eos_token_id=llm.tokenizer.eos_token_id,\n",
        "        pad_token_id=llm.tokenizer.eos_token_id,\n",
        "    )\n",
        "\n",
        "prompt_len = inputs[\"input_ids\"].shape[1]\n",
        "gen_ids = out[0, prompt_len:].tolist()\n",
        "\n",
        "print(\"gen_ids:\", gen_ids)\n",
        "print(\"decoded keep specials:\", repr(llm.tokenizer.decode(gen_ids, skip_special_tokens=False)))\n",
        "print(\"decoded skip specials:\", repr(llm.tokenizer.decode(gen_ids, skip_special_tokens=True)))\n",
        "print(\"eos_id:\", llm.tokenizer.eos_token_id)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_aplJxx9LBY",
        "outputId": "7edc8dd3-e82b-4831-b34f-6950adffb0c1"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gen_ids: [2]\n",
            "decoded keep specials: '<|im_end|>'\n",
            "decoded skip specials: ''\n",
            "eos_id: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from homework.base_llm import BaseLLM\n",
        "from peft import PeftModel\n",
        "\n",
        "llm = BaseLLM()\n",
        "llm.model = PeftModel.from_pretrained(llm.model, \"homework/sft_model\").to(llm.device)\n",
        "llm.model.eval()\n",
        "\n",
        "prompt = \"How many grams are there in 6 kg?\"\n",
        "llm.tokenizer.padding_side = \"left\"\n",
        "llm.tokenizer.pad_token = llm.tokenizer.eos_token\n",
        "inputs = llm.tokenizer([prompt], padding=True, return_tensors=\"pt\").to(llm.device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    out = llm.model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=20,\n",
        "        min_new_tokens=1,\n",
        "        do_sample=False,\n",
        "        eos_token_id=llm.tokenizer.eos_token_id,\n",
        "        pad_token_id=llm.tokenizer.eos_token_id,\n",
        "    )\n",
        "\n",
        "# show generated token ids after the prompt\n",
        "gen_ids = out[0, inputs[\"input_ids\"].shape[1]:].tolist()\n",
        "print(\"gen_ids:\", gen_ids)\n",
        "print(\"decoded:\", repr(llm.tokenizer.decode(gen_ids, skip_special_tokens=False)))\n"
      ],
      "metadata": {
        "id": "9_qy4c913VA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m homework.sft test --ckpt_path homework/sft_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dG-cTCo5744E",
        "outputId": "95b1431d-1e03-46aa-9408-f23824b8e3f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<frozen runpy>:128: RuntimeWarning: 'homework.sft' found in sys.modules after import of package 'homework', but prior to execution of 'homework.sft'; this may result in unpredictable behaviour\n",
            "2026-01-26 00:58:26.972488: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769389106.992232    6308 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769389106.998100    6308 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769389107.013110    6308 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769389107.013141    6308 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769389107.013145    6308 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769389107.013149    6308 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-26 00:58:27.017918: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "LLM Running on Micro Batches 32: 100% 4/4 [00:12<00:00,  3.22s/it]\n",
            "benchmark_result.accuracy=0.0  benchmark_result.answer_rate=0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "id": "6dtWHDvn0uNG",
        "outputId": "d944ca54-9948-4d2d-8bed-41f686902d96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m homework.datagen --output_json data/rft.json --oversample 10 --temperature 0.6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lki31SFq8D6r",
        "outputId": "551556ef-bbb0-419a-dde8-836338c9c2e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-01-26 01:18:18.166243: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769390298.185384   11408 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769390298.191251   11408 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769390298.206109   11408 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769390298.206136   11408 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769390298.206139   11408 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769390298.206143   11408 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-26 01:18:18.210714: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Wrote 514 / 1000 samples to data/rft.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-hUTjPMNMsb",
        "outputId": "337a4650-9e1d-4d90-b2ae-4c64e1e20bd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m homework.rft train --output_dir homework/rft_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_RO_sdd8V1p",
        "outputId": "ae014146-0ebd-46fb-f09a-3f20f2239852"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<frozen runpy>:128: RuntimeWarning: 'homework.rft' found in sys.modules after import of package 'homework', but prior to execution of 'homework.rft'; this may result in unpredictable behaviour\n",
            "2026-01-26 14:39:33.350335: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769438373.381732    3945 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769438373.391547    3945 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769438373.414731    3945 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769438373.414766    3945 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769438373.414774    3945 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769438373.414780    3945 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-26 14:39:33.421509: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "  0% 0/51 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
            "{'loss': 0.7414, 'grad_norm': 0.418857604265213, 'learning_rate': 0.00011020408163265306, 'epoch': 1.47}\n",
            "{'loss': 0.2812, 'grad_norm': 0.3334137797355652, 'learning_rate': 8.163265306122448e-06, 'epoch': 2.94}\n",
            "{'train_runtime': 71.4153, 'train_samples_per_second': 21.592, 'train_steps_per_second': 0.714, 'train_loss': 0.5061353266823525, 'epoch': 3.0}\n",
            "100% 51/51 [01:11<00:00,  1.40s/it]\n",
            "LLM Running on Micro Batches 32: 100% 4/4 [00:14<00:00,  3.51s/it]\n",
            "benchmark_result.accuracy=0.3  benchmark_result.answer_rate=0.52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m homework.rft test --ckpt_path homework/rft_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nCzpXHFLONk",
        "outputId": "ac1a3d71-4e81-45de-efe6-a5735fef65ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<frozen runpy>:128: RuntimeWarning: 'homework.rft' found in sys.modules after import of package 'homework', but prior to execution of 'homework.rft'; this may result in unpredictable behaviour\n",
            "2026-01-26 01:35:33.493794: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769391333.513485   15845 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769391333.519652   15845 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769391333.535137   15845 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769391333.535170   15845 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769391333.535174   15845 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769391333.535178   15845 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-26 01:35:33.539983: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "LLM Running on Micro Batches 32: 100% 4/4 [00:14<00:00,  3.63s/it]\n",
            "benchmark_result.accuracy=0.55  benchmark_result.answer_rate=0.86\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WODRADDO02Hd"
      },
      "source": [
        "## Grader\n",
        "\n",
        "Run the following cell to grade your homework.\n",
        "\n",
        "Note: if you don't set up PySuperTuxKart, the grader will not run the driving tests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ijkV65Bvpaj",
        "outputId": "ea412804-53fd-4ef5-c2b5-857461f545e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val grader loaded.\n",
            "[DEBUG    00:00:000] Loading assignment\n",
            "[DEBUG    00:02:804] Loading grader\n",
            "[INFO     00:02:805] Model non-batched inference grader\n",
            "2026-01-26 01:36:09.033757: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769391369.053768   16008 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769391369.059652   16008 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769391369.076196   16008 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769391369.076225   16008 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769391369.076229   16008 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769391369.076236   16008 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-26 01:36:09.081447: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "100% 32/32 [00:05<00:00,  6.20it/s]\n",
            "[WARNING  00:17:223]   - Test non-batched generate function                 [ 10 / 10  ]\n",
            "WARNING:grader:  - Test non-batched generate function                 [ 10 / 10  ]\n",
            "[INFO     00:17:224]  --------------------------------------------------    [  10 /  10 ]\n",
            "INFO:grader: --------------------------------------------------    [  10 /  10 ]\n",
            "[INFO     00:17:224] Model batched inference grader\n",
            "INFO:grader:Model batched inference grader\n",
            "[WARNING  00:21:145]   - Test batched generate function                     [ 15 / 15  ]\n",
            "WARNING:grader:  - Test batched generate function                     [ 15 / 15  ]\n",
            "[INFO     00:21:145]  --------------------------------------------------    [  15 /  15 ]\n",
            "INFO:grader: --------------------------------------------------    [  15 /  15 ]\n",
            "[INFO     00:21:146] CoT Model Grader\n",
            "INFO:grader:CoT Model Grader\n",
            "LLM Running on Micro Batches 32: 100% 4/4 [00:10<00:00,  2.57s/it]\n",
            "[DEBUG    00:32:942] 0.23\n",
            "DEBUG:grader:0.23\n",
            "[WARNING  00:32:953]   - Test the answer accuracy                           [ 14 / 25  ]\n",
            "WARNING:grader:  - Test the answer accuracy                           [ 14 / 25  ]\n",
            "[INFO     00:32:953]  --------------------------------------------------    [  14 /  25 ]\n",
            "INFO:grader: --------------------------------------------------    [  14 /  25 ]\n",
            "[INFO     00:32:954] SFT Model Grader\n",
            "INFO:grader:SFT Model Grader\n",
            "LLM Running on Micro Batches 32: 100% 4/4 [00:12<00:00,  3.21s/it]\n",
            "[DEBUG    00:47:799] 0.0\n",
            "DEBUG:grader:0.0\n",
            "[WARNING  00:47:814]   - Test the answer accuracy                           [ 0 / 25  ]\n",
            "WARNING:grader:  - Test the answer accuracy                           [ 0 / 25  ]\n",
            "[INFO     00:47:814]  --------------------------------------------------    [   0 /  25 ]\n",
            "INFO:grader: --------------------------------------------------    [   0 /  25 ]\n",
            "[INFO     00:47:814] RFT Model Grader\n",
            "INFO:grader:RFT Model Grader\n",
            "LLM Running on Micro Batches 32: 100% 4/4 [00:14<00:00,  3.57s/it]\n",
            "[DEBUG    01:04:253] 0.55\n",
            "DEBUG:grader:0.55\n",
            "[WARNING  01:04:270]   - Test the answer accuracy                           [ 0 / 25  ]\n",
            "WARNING:grader:  - Test the answer accuracy                           [ 0 / 25  ]\n",
            "[INFO     01:04:271]  --------------------------------------------------    [   0 /  25 ]\n",
            "INFO:grader: --------------------------------------------------    [   0 /  25 ]\n",
            "[INFO     01:04:271] Total                                                     39 / 100\n",
            "INFO:grader:Total                                                     39 / 100\n"
          ]
        }
      ],
      "source": [
        "!python3 -m grader homework -vv --disable_color"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzPcTJQxvYQR",
        "outputId": "0b314d28-c48a-4ef1-e002-2d176b37f6ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bundle.py  \u001b[0m\u001b[01;34mgrader\u001b[0m/    Homework3.ipynb  requirements.txt\n",
            "\u001b[01;34mdata\u001b[0m/      \u001b[01;34mhomework\u001b[0m/  README.md\n",
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\t\u001b[31mdata/rft.json\u001b[m\n",
            "\t\u001b[31mhomework/rft_model/\u001b[m\n",
            "\t\u001b[31mhomework/sft_model/\u001b[m\n",
            "\n",
            "nothing added to commit but untracked files present (use \"git add\" to track)\n"
          ]
        }
      ],
      "source": [
        "%ls\n",
        "!git status"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "id": "pVOEEkb_bz-P",
        "outputId": "dddba19a-9540-4308-8e3e-cb507c3cb294",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiUnZ58P0iZF",
        "outputId": "5ec3b8d7-8e81-489d-e4d4-bfda590d1f14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[main 7aba4473] colab update\n",
            " 1 file changed, 0 insertions(+), 0 deletions(-)\n",
            " create mode 100644 homework2/ca37464.zip\n",
            "Enumerating objects: 6, done.\n",
            "Counting objects: 100% (6/6), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (4/4), 7.85 MiB | 13.77 MiB/s, done.\n",
            "Total 4 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/chaalp/advances_in_deep_learning.git\n",
            "   ca0fa9c1..7aba4473  main -> main\n"
          ]
        }
      ],
      "source": [
        "# Be careful not to \"git add *\" since there are datasets and logs\n",
        "!git add .\n",
        "!git config --global user.email \"chander_alphonse@yahoo.com\"\n",
        "!git config --global user.name \"chaalp\"\n",
        "!git commit -m \"colab update\"\n",
        "!git push"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiCe-RX-J6CF"
      },
      "source": [
        "## Update your changes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxbPtnF55AMU"
      },
      "source": [
        "## Submission\n",
        "\n",
        "Run the following cell to bundle your submission (modify UTID accordingly).\n",
        "\n",
        "If you notice that your bundle is too large, you can modify the `bundle.py` script and ignore large files by adding them manually to `BLACKLIST`.\n",
        "\n",
        "After the bundler and grader run, right click and download your bundled `.zip` file from the Colab UI.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M07WA1Os4Xxh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "433560bb-eeac-4b1c-9a2f-27c9f62a3ae9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokenize.py\n",
            "data.py\n",
            "__init__.py\n",
            "ae.py\n",
            "bsq.py\n",
            "train.py\n",
            "generation.py\n",
            "compress.py\n",
            "PatchAutoEncoder.pth\n",
            "AutoregressiveModel.pth\n",
            "BSQPatchAutoEncoder.pth\n",
            "autoregressive.py\n",
            "Submission created: /content/advances_in_deep_learning/homework2/ca37464.zip 7.85 MB\n",
            "Val grader loaded.\n",
            "[DEBUG    00:00:000] Loading assignment\n",
            "[DEBUG    00:00:088] Loading grader\n",
            "[INFO     00:00:089] Patch AutoEncoder\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[DEBUG    00:00:100] Loading PatchAutoEncoder from /tmp/tmpe52uuqhj/homework/PatchAutoEncoder.pth\n",
            "[DEBUG    00:02:018] Validation loss: 0.005878145806491375\n",
            "[WARNING  00:02:019]   - Image Reconstruction MSE Loss                      [ 30 / 30  ]\n",
            "[INFO     00:02:020]  --------------------------------------------------    [  30 /  30 ]\n",
            "[INFO     00:02:020] BSQ Patch AutoEncoder\n",
            "[DEBUG    00:02:031] Loading BSQPatchAutoEncoder from /tmp/tmpe52uuqhj/homework/BSQPatchAutoEncoder.pth\n",
            "[DEBUG    00:03:758] Validation loss: 0.004041745327413082\n",
            "[WARNING  00:03:760]   - Image Reconstruction MSE Loss                      [ 30 / 30  ]\n",
            "[INFO     00:03:760]  --------------------------------------------------    [  30 /  30 ]\n",
            "[INFO     00:03:761] Autoregressive Model\n",
            "[DEBUG    00:03:772] Loading AutoregressiveModel from /tmp/tmpe52uuqhj/homework/AutoregressiveModel.pth\n",
            "[DEBUG    00:03:786] Loading BSQPatchAutoEncoder from /tmp/tmpe52uuqhj/homework/BSQPatchAutoEncoder.pth\n",
            "Compute validation autoregressive loss:   0% 0/40 [00:00<?, ?it/s][DEBUG    00:04:325] loss: 2765.43408203125\n",
            "Compute validation autoregressive loss:   2% 1/40 [00:00<00:20,  1.87it/s][DEBUG    00:04:420] loss: 2626.9951171875\n",
            "[DEBUG    00:04:509] loss: 2689.6494140625\n",
            "Compute validation autoregressive loss:   8% 3/40 [00:00<00:07,  4.85it/s][DEBUG    00:04:599] loss: 2740.5009765625\n",
            "[DEBUG    00:04:687] loss: 2799.07177734375\n",
            "Compute validation autoregressive loss:  12% 5/40 [00:00<00:05,  6.85it/s][DEBUG    00:04:777] loss: 2667.234619140625\n",
            "[DEBUG    00:04:866] loss: 2748.378173828125\n",
            "Compute validation autoregressive loss:  18% 7/40 [00:01<00:04,  8.19it/s][DEBUG    00:04:955] loss: 2894.95068359375\n",
            "[DEBUG    00:05:044] loss: 2782.253662109375\n",
            "Compute validation autoregressive loss:  22% 9/40 [00:01<00:03,  9.12it/s][DEBUG    00:05:133] loss: 2713.906494140625\n",
            "[DEBUG    00:05:227] loss: 2679.927734375\n",
            "Compute validation autoregressive loss:  28% 11/40 [00:01<00:02,  9.68it/s][DEBUG    00:05:315] loss: 2610.4541015625\n",
            "[DEBUG    00:05:405] loss: 2699.767333984375\n",
            "Compute validation autoregressive loss:  32% 13/40 [00:01<00:02, 10.15it/s][DEBUG    00:05:498] loss: 2830.227294921875\n",
            "[DEBUG    00:05:589] loss: 2834.3486328125\n",
            "Compute validation autoregressive loss:  38% 15/40 [00:01<00:02, 10.37it/s][DEBUG    00:05:677] loss: 2797.982421875\n",
            "[DEBUG    00:05:776] loss: 2805.5234375\n",
            "Compute validation autoregressive loss:  42% 17/40 [00:01<00:02, 10.47it/s][DEBUG    00:05:869] loss: 2703.28759765625\n",
            "[DEBUG    00:05:958] loss: 2708.708740234375\n",
            "Compute validation autoregressive loss:  48% 19/40 [00:02<00:01, 10.61it/s][DEBUG    00:06:047] loss: 2717.50732421875\n",
            "[DEBUG    00:06:137] loss: 2834.374755859375\n",
            "Compute validation autoregressive loss:  52% 21/40 [00:02<00:01, 10.78it/s][DEBUG    00:06:225] loss: 2659.37841796875\n",
            "[DEBUG    00:06:323] loss: 2736.813720703125\n",
            "Compute validation autoregressive loss:  57% 23/40 [00:02<00:01, 10.78it/s][DEBUG    00:06:417] loss: 2871.53076171875\n",
            "[DEBUG    00:06:508] loss: 2800.853515625\n",
            "Compute validation autoregressive loss:  62% 25/40 [00:02<00:01, 10.79it/s][DEBUG    00:06:602] loss: 2750.362060546875\n",
            "[DEBUG    00:06:693] loss: 2834.1533203125\n",
            "Compute validation autoregressive loss:  68% 27/40 [00:02<00:01, 10.79it/s][DEBUG    00:06:786] loss: 2839.320068359375\n",
            "[DEBUG    00:06:872] loss: 2729.368896484375\n",
            "Compute validation autoregressive loss:  72% 29/40 [00:03<00:01, 10.90it/s][DEBUG    00:06:961] loss: 2806.20703125\n",
            "[DEBUG    00:07:051] loss: 2737.31689453125\n",
            "Compute validation autoregressive loss:  78% 31/40 [00:03<00:00, 10.99it/s][DEBUG    00:07:143] loss: 2745.277099609375\n",
            "[DEBUG    00:07:232] loss: 2720.09619140625\n",
            "Compute validation autoregressive loss:  82% 33/40 [00:03<00:00, 11.01it/s][DEBUG    00:07:320] loss: 2816.864013671875\n",
            "[DEBUG    00:07:409] loss: 2773.227783203125\n",
            "Compute validation autoregressive loss:  88% 35/40 [00:03<00:00, 11.08it/s][DEBUG    00:07:498] loss: 2646.795654296875\n",
            "[DEBUG    00:07:587] loss: 2749.90966796875\n",
            "Compute validation autoregressive loss:  92% 37/40 [00:03<00:00, 11.14it/s][DEBUG    00:07:677] loss: 2701.375244140625\n",
            "[DEBUG    00:07:764] loss: 2643.17529296875\n",
            "Compute validation autoregressive loss:  98% 39/40 [00:03<00:00, 11.18it/s][DEBUG    00:07:852] loss: 2629.1298828125\n",
            "Compute validation autoregressive loss: 100% 40/40 [00:04<00:00,  9.75it/s]\n",
            "[DEBUG    00:07:895] Validation loss: 2746.0409973144533\n",
            "[WARNING  00:07:896]   - Autoregressive prediction loss                     [ 15 / 15  ]\n",
            "[DEBUG    00:07:897] Loading AutoregressiveModel from /tmp/tmpe52uuqhj/homework/AutoregressiveModel.pth\n",
            "[DEBUG    00:07:910] Loading BSQPatchAutoEncoder from /tmp/tmpe52uuqhj/homework/BSQPatchAutoEncoder.pth\n",
            "[DEBUG    00:08:164] token change ratio: 0.43\n",
            "[WARNING  00:08:166]   - Check autoregressiveness of the model              [ 15 / 15  ]\n",
            "[INFO     00:08:166]  --------------------------------------------------    [  30 /  30 ]\n",
            "[INFO     00:08:166] Image Generation from Autoregressive Model\n",
            "[DEBUG    00:08:167] Loading AutoregressiveModel from /tmp/tmpe52uuqhj/homework/AutoregressiveModel.pth\n",
            "[DEBUG    00:08:180] Loading BSQPatchAutoEncoder from /tmp/tmpe52uuqhj/homework/BSQPatchAutoEncoder.pth\n",
            "[DEBUG    00:08:185] generating 8 images from the autoregressive model\n",
            "[DEBUG    00:14:563] Generation NLL: 2.999892473220825\n",
            "[WARNING  00:14:574]   - Check image generation from the model              [ 10 / 10  ]\n",
            "[INFO     00:14:574]  --------------------------------------------------    [  10 /  10 ]\n",
            "[INFO     00:14:574] Image Compression\n",
            "[DEBUG    00:14:577] Loading AutoregressiveModel from /tmp/tmpe52uuqhj/homework/AutoregressiveModel.pth\n",
            "[DEBUG    00:14:589] Loading BSQPatchAutoEncoder from /tmp/tmpe52uuqhj/homework/BSQPatchAutoEncoder.pth\n",
            "Checking compression:   0% 0/5 [00:00<?, ?it/s]\n",
            "[WARNING  00:14:603]   - Check image compression ratio and reconstruction quality [ 0 / 5 Not Implemented ]\n",
            "[INFO     00:14:603]  --------------------------------------------------    [   0 /   5 ]\n",
            "[INFO     00:14:603] Total                                                    100 / 105\n"
          ]
        }
      ],
      "source": [
        "!python3 bundle.py homework ca37464\n",
        "\n",
        "# optional: run the grader with your bundled homework to double check\n",
        "!python3 -m grader ca37464.zip -vv --disable_color"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}